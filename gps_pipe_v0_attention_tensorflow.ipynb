{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "175a72c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "feature_store_env = '/home/ec2-user/SageMaker/custom-miniconda/miniconda/envs/feature_store/lib/python3.8/site-packages'\n",
    "sys.path.append(feature_store_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "288b7acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dateutil.tz\n",
    "import datetime as dt\n",
    "import json\n",
    "import awswrangler as wr\n",
    "from feature_store import feature_store\n",
    "from feature_store.feature_table import feature_table\n",
    "from feature_store.value_type import ValueType\n",
    "import feature_store.config as config\n",
    "from io import StringIO\n",
    "import urllib3\n",
    "import logging\n",
    "import sys\n",
    "from json import dumps\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "def get_ymd(datetime):\n",
    "    year = datetime.year\n",
    "    month = datetime.month\n",
    "    day = datetime.day\n",
    "            \n",
    "    if month < 10:\n",
    "        month = '0' + str(month)\n",
    "    if day < 10:\n",
    "        day = '0' + str(day)\n",
    "    return year, month, day\n",
    "\n",
    "def first_day_next_month(date):\n",
    "    return (date.replace(day=1) + dt.timedelta(days=32)).replace(day=1)\n",
    "\n",
    "def last_second_of_month(date: str) -> str:\n",
    "    return str((pd.Timestamp(date) + pd.offsets.MonthEnd(0)).date()) + \" 23:59:59\"\n",
    "\n",
    "def first_second_of_month(date: str) -> str:\n",
    "    return str((pd.Timestamp(date) + pd.offsets.MonthBegin(0)).date()) + \" 00:00:00\"\n",
    "\n",
    "streamer = StringIO()\n",
    "\n",
    "def setup_logging():\n",
    "    logger = logging.getLogger()\n",
    "    for h in logger.handlers:\n",
    "        logger.removeHandler(h)\n",
    "     \n",
    "    h = logging.StreamHandler(stream = streamer)\n",
    "    h.setFormatter(logging.Formatter(\"%(asctime)s %(levelname)s: %(message)s\",\n",
    "                              \"%Y-%m-%d %H:%M:%S\"))\n",
    "    logger.addHandler(h)\n",
    "    logger.setLevel(logging.INFO)\n",
    "    return logger\n",
    "\n",
    "def query_log(query_id, table, logger):\n",
    "    status = wr.athena.get_query_execution(query_id)['Status']['State']\n",
    "    if wr.athena.get_query_execution(query_id)['Status']['State'] in ['FAILED', 'CANCELLED']:\n",
    "        logger.critical(table + ': query is in ' + status + ' State. ' + 'QueryID: ' + query_id)\n",
    "    else:\n",
    "        logger.info(table + ': query is in ' + status + ' State. ' + 'QueryID: ' + query_id)\n",
    "    return None\n",
    "\n",
    "http = urllib3.PoolManager()\n",
    "url = 'https://chat.googleapis.com/v1/spaces/AAAALuxU48o/messages?key=AIzaSyDdI0hCZtE6vySjMm-WEfRq3CPzqKqqsHI&token=T1j8SVrn051V2f9q0wxFMbbI5DkIH2IKTxPYy3TnP9Q%3D'\n",
    "fs = feature_store.feature_store()\n",
    "\n",
    "zone = dateutil.tz.gettz('Asia/Calcutta')\n",
    "\n",
    "logger = setup_logging()\n",
    "\n",
    "now = dt.datetime.now(zone)\n",
    "current_hour = now.replace(minute=0, second=0, microsecond=0)\n",
    "current_hour_s = current_hour.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "def query_progress(query_id, run_async, table_name):\n",
    "    if not run_async:\n",
    "            status = wr.athena.get_query_execution(query_id)['Status']['State']\n",
    "            while status not in ('SUCCEEDED'):\n",
    "                if status in ['RUNNING', 'QUEUED']:\n",
    "                    status = wr.athena.get_query_execution(query_id)['Status']['State']\n",
    "                elif status == 'FAILED':\n",
    "                    print('Query Failed')\n",
    "                    break\n",
    "                elif status == 'CANCELLED':\n",
    "                    print('Query Cancelled')\n",
    "                    break\n",
    "    else:\n",
    "        status = wr.athena.get_query_execution(query_id)['Status']['State']\n",
    "        while status not in ('RUNNING'):\n",
    "            if status == 'QUEUED':\n",
    "                time.sleep(2)\n",
    "                status = wr.athena.get_query_execution(query_id)['Status']['State']\n",
    "            elif status == 'SUCCEEDED':\n",
    "                print('Query Succeeded')\n",
    "                break\n",
    "            elif status == 'FAILED':\n",
    "                print('Query Failed')\n",
    "                break\n",
    "            elif status == 'CANCELLED':\n",
    "                print('Query Cancelled')\n",
    "                break\n",
    "    query_log(query_id, table_name, logger)\n",
    "    return status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58eebe23",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "    with sp_mapping_temp as (\n",
    "    SELECT  id as fleet_owner_id, max_by(cast(phone_no as varchar), updated_at) as mobile_no,\n",
    "    max_by(cast(iam_id as int), updated_at) as sp_id  FROM  \"awsdatacatalog\".\"supply_team\".\"supply_team_blackbuck_fleetapp_fleetowner\"\n",
    "    group by 1\n",
    "    ),\n",
    "\n",
    "    sp_mapping as (\n",
    "    select fleet_owner_id, mobile_no, cast(sp_id as bigint) as sp_id \n",
    "    from sp_mapping_temp \n",
    "    where mobile_no in (\n",
    "    select mobile_no from (\n",
    "    select mobile_no, count(*) as sp_count from sp_mapping_temp\n",
    "    group by 1\n",
    "    having count(*)<=1))\n",
    "    ),\n",
    "\n",
    "    --- Truck Mapping to SP ID\n",
    "    truck_mapping as (\n",
    "    select ft.id as truck_id,\n",
    "    ft.truck_no as truck_number,\n",
    "    tor.fleet_owner_id as fleet_owner_id,\n",
    "    s.sp_id\n",
    "    from \"awsdatacatalog\".\"supply_team\".\"supply_team_blackbuck_fleetapp_truck\" ft\n",
    "    inner join \"awsdatacatalog\".\"supply_team\".\"supply_team_blackbuck_truck_owner_request\" tor on ft.id = tor.truck_id\n",
    "    inner join sp_mapping s on s.fleet_owner_id = tor.fleet_owner_id\n",
    "    where \n",
    "    ft.truck_no != ''\n",
    "    and tor.fleet_owner_id is not null\n",
    "    and tor.kyc_status_v2 ='APPROVED'\n",
    "    and ft.is_truck = 'VERIFIED'\n",
    "    and ft.is_verified != 3\n",
    "    group by 1,2,3,4\n",
    "    ),\n",
    "\n",
    "    --- Single Truck FOs/SPs\n",
    "    single_truck_sps as (\n",
    "    select\n",
    "    tm.*,\n",
    "    tmc.number_of_trucks\n",
    "    from truck_mapping tm\n",
    "    left join (select sp_id, count(distinct truck_number) as number_of_trucks from truck_mapping group by 1) tmc on tmc.sp_id = tm.sp_id\n",
    "    where tmc.number_of_trucks = 1\n",
    "    ),\n",
    "\n",
    "    ------ Plaza to District Mapping\n",
    "    district_boundaries as (\n",
    "    select place_id as district_id, \n",
    "    name as district_name, \n",
    "    ST_GeomFromBinary(from_hex(to_utf8(replace(boundary_geog,'20E61000')))) as boundary_geog,\n",
    "    ST_X(ST_Centroid(ST_GeomFromBinary(from_hex(to_utf8(replace(boundary_geog,'20E61000')))))) as longitude,\n",
    "    ST_Y(ST_Centroid(ST_GeomFromBinary(from_hex(to_utf8(replace(boundary_geog,'20E61000')))))) as latitude\n",
    "    from location_service.public.admin_area where deleted = false\n",
    "    and local_tag = 'DISTRICT'\n",
    "    and boundary_geog != ''\n",
    "    ),\n",
    "\n",
    "    distict_distance as (\n",
    "    select a.district_id as from_district_id,\n",
    "    b.district_id as to_district_id,\n",
    "    cast(great_circle_distance(a.latitude, a.longitude, b.latitude, b.longitude) as int) as distance\n",
    "    from district_boundaries a\n",
    "    cross join district_boundaries b\n",
    "    ),\n",
    "\n",
    "    ---- Semantics District Vectors\n",
    "    semantics_score_district_temp as (\n",
    "        SELECT *\n",
    "        FROM (\n",
    "                SELECT t.*,\n",
    "                    ROW_NUMBER() OVER (\n",
    "                        PARTITION BY bb_place_id\n",
    "                        ORDER BY created_timestamp DESC\n",
    "                    ) AS rnk\n",
    "                FROM \"awsdatacatalog\".\"feature_store\".\"semantics_from_district\" t\n",
    "            )\n",
    "        WHERE rnk = 1\n",
    "    ),\n",
    "\n",
    "    semantics_score_district_map as (\n",
    "        select bb_place_id as district_id,\n",
    "            MAP_FROM_ENTRIES(\n",
    "                ARRAY [ ('f_1', f_1),\n",
    "                ('f_2', f_2),\n",
    "                ('f_3', f_3),\n",
    "                ('f_4', f_4),\n",
    "                ('f_5', f_5),\n",
    "                ('f_6', f_6),\n",
    "                ('f_7', f_7),\n",
    "                ('f_8', f_8),\n",
    "                ('f_9', f_9),\n",
    "                ('f_10', f_10),\n",
    "                ('f_11', f_11),\n",
    "                ('f_12', f_12),\n",
    "                ('f_13', f_13),\n",
    "                ('f_14', f_14),\n",
    "                ('f_15', f_15),\n",
    "                ('f_16', f_16),\n",
    "                ('f_17', f_17),\n",
    "                ('f_18', f_18),\n",
    "                ('f_19', f_19),\n",
    "                ('f_20', f_20),\n",
    "                ('f_21', f_21),\n",
    "                ('f_22', f_22),\n",
    "                ('f_23', f_23),\n",
    "                ('f_24', f_24),\n",
    "                ('f_25', f_25),\n",
    "                ('f_26', f_26),\n",
    "                ('f_27', f_27),\n",
    "                ('f_28', f_28),\n",
    "                ('f_29', f_29),\n",
    "                ('f_30', f_30),\n",
    "                ('f_31', f_31),\n",
    "                ('f_32', f_32),\n",
    "                ('f_33', f_33),\n",
    "                ('f_34', f_34),\n",
    "                ('f_35', f_35),\n",
    "                ('f_36', f_36),\n",
    "                ('f_37', f_37),\n",
    "                ('f_38', f_38),\n",
    "                ('f_39', f_39),\n",
    "                ('f_40', f_40),\n",
    "                ('f_41', f_41),\n",
    "                ('f_42', f_42),\n",
    "                ('f_43', f_43),\n",
    "                ('f_44', f_44),\n",
    "                ('f_45', f_45),\n",
    "                ('f_46', f_46),\n",
    "                ('f_47', f_47),\n",
    "                ('f_48', f_48),\n",
    "                ('f_49', f_49),\n",
    "                ('f_50', f_50),\n",
    "                ('f_51', f_51),\n",
    "                ('f_52', f_52),\n",
    "                ('f_53', f_53),\n",
    "                ('f_54', f_54),\n",
    "                ('f_55', f_55),\n",
    "                ('f_56', f_56),\n",
    "                ('f_57', f_57),\n",
    "                ('f_58', f_58),\n",
    "                ('f_59', f_59),\n",
    "                ('f_60', f_60),\n",
    "                ('f_61', f_61),\n",
    "                ('f_62', f_62),\n",
    "                ('f_63', f_63),\n",
    "                ('f_64', f_64),\n",
    "                ('f_65', f_65),\n",
    "                ('f_66', f_66),\n",
    "                ('f_67', f_67),\n",
    "                ('f_68', f_68),\n",
    "                ('f_69', f_69),\n",
    "                ('f_70', f_70),\n",
    "                ('f_71', f_71),\n",
    "                ('f_72', f_72),\n",
    "                ('f_73', f_73),\n",
    "                ('f_74', f_74),\n",
    "                ('f_75', f_75),\n",
    "                ('f_76', f_76),\n",
    "                ('f_77', f_77),\n",
    "                ('f_78', f_78),\n",
    "                ('f_79', f_79),\n",
    "                ('f_80', f_80),\n",
    "                ('f_81', f_81),\n",
    "                ('f_82', f_82),\n",
    "                ('f_83', f_83),\n",
    "                ('f_84', f_84),\n",
    "                ('f_85', f_85),\n",
    "                ('f_86', f_86),\n",
    "                ('f_87', f_87),\n",
    "                ('f_88', f_88),\n",
    "                ('f_89', f_89),\n",
    "                ('f_90', f_90),\n",
    "                ('f_91', f_91),\n",
    "                ('f_92', f_92),\n",
    "                ('f_93', f_93),\n",
    "                ('f_94', f_94),\n",
    "                ('f_95', f_95),\n",
    "                ('f_96', f_96),\n",
    "                ('f_97', f_97),\n",
    "                ('f_98', f_98),\n",
    "                ('f_99', f_99),\n",
    "                ('f_100', f_100),\n",
    "                ('f_101', f_101),\n",
    "                ('f_102', f_102),\n",
    "                ('f_103', f_103),\n",
    "                ('f_104', f_104),\n",
    "                ('f_105', f_105),\n",
    "                ('f_106', f_106),\n",
    "                ('f_107', f_107),\n",
    "                ('f_108', f_108),\n",
    "                ('f_109', f_109),\n",
    "                ('f_110', f_110),\n",
    "                ('f_111', f_111),\n",
    "                ('f_112', f_112),\n",
    "                ('f_113', f_113),\n",
    "                ('f_114', f_114),\n",
    "                ('f_115', f_115),\n",
    "                ('f_116', f_116),\n",
    "                ('f_117', f_117),\n",
    "                ('f_118', f_118),\n",
    "                ('f_119', f_119),\n",
    "                ('f_120', f_120),\n",
    "                ('f_121', f_121),\n",
    "                ('f_122', f_122),\n",
    "                ('f_123', f_123),\n",
    "                ('f_124', f_124),\n",
    "                ('f_125', f_125),\n",
    "                ('f_126', f_126),\n",
    "                ('f_127', f_127),\n",
    "                ('f_128', f_128),\n",
    "                ('f_129', f_129),\n",
    "                ('f_130', f_130),\n",
    "                ('f_131', f_131),\n",
    "                ('f_132', f_132),\n",
    "                ('f_133', f_133),\n",
    "                ('f_134', f_134),\n",
    "                ('f_135', f_135),\n",
    "                ('f_136', f_136),\n",
    "                ('f_137', f_137),\n",
    "                ('f_138', f_138),\n",
    "                ('f_139', f_139),\n",
    "                ('f_140', f_140),\n",
    "                ('f_141', f_141),\n",
    "                ('f_142', f_142),\n",
    "                ('f_143', f_143),\n",
    "                ('f_144', f_144),\n",
    "                ('f_145', f_145),\n",
    "                ('f_146', f_146),\n",
    "                ('f_147', f_147),\n",
    "                ('f_148', f_148),\n",
    "                ('f_149', f_149),\n",
    "                ('f_150', f_150),\n",
    "                ('f_151', f_151),\n",
    "                ('f_152', f_152),\n",
    "                ('f_153', f_153),\n",
    "                ('f_154', f_154),\n",
    "                ('f_155', f_155),\n",
    "                ('f_156', f_156),\n",
    "                ('f_157', f_157),\n",
    "                ('f_158', f_158),\n",
    "                ('f_159', f_159),\n",
    "                ('f_160', f_160),\n",
    "                ('f_161', f_161),\n",
    "                ('f_162', f_162),\n",
    "                ('f_163', f_163),\n",
    "                ('f_164', f_164),\n",
    "                ('f_165', f_165),\n",
    "                ('f_166', f_166),\n",
    "                ('f_167', f_167),\n",
    "                ('f_168', f_168),\n",
    "                ('f_169', f_169),\n",
    "                ('f_170', f_170),\n",
    "                ('f_171', f_171),\n",
    "                ('f_172', f_172),\n",
    "                ('f_173', f_173),\n",
    "                ('f_174', f_174),\n",
    "                ('f_175', f_175),\n",
    "                ('f_176', f_176),\n",
    "                ('f_177', f_177),\n",
    "                ('f_178', f_178),\n",
    "                ('f_179', f_179),\n",
    "                ('f_180', f_180),\n",
    "                ('f_181', f_181),\n",
    "                ('f_182', f_182),\n",
    "                ('f_183', f_183),\n",
    "                ('f_184', f_184),\n",
    "                ('f_185', f_185),\n",
    "                ('f_186', f_186),\n",
    "                ('f_187', f_187),\n",
    "                ('f_188', f_188),\n",
    "                ('f_189', f_189),\n",
    "                ('f_190', f_190),\n",
    "                ('f_191', f_191),\n",
    "                ('f_192', f_192),\n",
    "                ('f_193', f_193),\n",
    "                ('f_194', f_194),\n",
    "                ('f_195', f_195),\n",
    "                ('f_196', f_196),\n",
    "                ('f_197', f_197),\n",
    "                ('f_198', f_198),\n",
    "                ('f_199', f_199),\n",
    "                ('f_200', f_200),\n",
    "                ('f_201', f_201),\n",
    "                ('f_202', f_202),\n",
    "                ('f_203', f_203),\n",
    "                ('f_204', f_204),\n",
    "                ('f_205', f_205),\n",
    "                ('f_206', f_206),\n",
    "                ('f_207', f_207),\n",
    "                ('f_208', f_208),\n",
    "                ('f_209', f_209),\n",
    "                ('f_210', f_210),\n",
    "                ('f_211', f_211),\n",
    "                ('f_212', f_212),\n",
    "                ('f_213', f_213),\n",
    "                ('f_214', f_214),\n",
    "                ('f_215', f_215),\n",
    "                ('f_216', f_216),\n",
    "                ('f_217', f_217),\n",
    "                ('f_218', f_218),\n",
    "                ('f_219', f_219),\n",
    "                ('f_220', f_220),\n",
    "                ('f_221', f_221),\n",
    "                ('f_222', f_222),\n",
    "                ('f_223', f_223),\n",
    "                ('f_224', f_224),\n",
    "                ('f_225', f_225),\n",
    "                ('f_226', f_226),\n",
    "                ('f_227', f_227),\n",
    "                ('f_228', f_228),\n",
    "                ('f_229', f_229),\n",
    "                ('f_230', f_230),\n",
    "                ('f_231', f_231),\n",
    "                ('f_232', f_232),\n",
    "                ('f_233', f_233),\n",
    "                ('f_234', f_234),\n",
    "                ('f_235', f_235),\n",
    "                ('f_236', f_236),\n",
    "                ('f_237', f_237),\n",
    "                ('f_238', f_238),\n",
    "                ('f_239', f_239),\n",
    "                ('f_240', f_240),\n",
    "                ('f_241', f_241),\n",
    "                ('f_242', f_242),\n",
    "                ('f_243', f_243),\n",
    "                ('f_244', f_244),\n",
    "                ('f_245', f_245),\n",
    "                ('f_246', f_246),\n",
    "                ('f_247', f_247),\n",
    "                ('f_248', f_248),\n",
    "                ('f_249', f_249),\n",
    "                ('f_250', f_250) ]\n",
    "            ) as features,\n",
    "            1 as key\n",
    "        from semantics_score_district_temp\n",
    "    ),\n",
    "\n",
    "    district_similarity as (\n",
    "    select a.district_id as from_district_id,\n",
    "        b.district_id as to_district_id,\n",
    "        cast(\n",
    "            round(cosine_similarity(a.features, b.features), 2) * 100 as int\n",
    "        ) as similarity\n",
    "    from semantics_score_district_map a\n",
    "        left join semantics_score_district_map b on a.key = b.key\n",
    "    group by 1, 2, 3\n",
    "    ),\n",
    "\n",
    "    output as (\n",
    "    select * from awsdatacatalog.feature_store.avl_training_output_v2\n",
    "    where sp_id in (select sp_id from single_truck_sps)\n",
    "    and district_id in (select district_id from district_boundaries)\n",
    "    ),\n",
    "    --- Merge Output with GPS Transactions data\n",
    "    gps_merge_temp as (\n",
    "    select o.*,\n",
    "    s.truck_number,\n",
    "    gps.entity as district_id_gps,\n",
    "    gps.event_timestamp as event_timestamp_gps,\n",
    "    gps.total_dwell_time,\n",
    "    gps.total_speed,\n",
    "    gps.total_is_ignition_off,\n",
    "    gps.total_records,\n",
    "    d.distance,\n",
    "\n",
    "    case\n",
    "        when gps.entity = LAG(gps.entity, 1) OVER (PARTITION BY o.id ORDER BY gps.event_timestamp DESC) then 0\n",
    "\n",
    "        else 1\n",
    "    end as flag,\n",
    "    date_diff('day',gps.event_timestamp,o.event_timestamp) as time_diff,\n",
    "    case\n",
    "        when date_diff('day',gps.event_timestamp,o.event_timestamp)<=1 then 'day_1'\n",
    "         when date_diff('day',gps.event_timestamp,o.event_timestamp)<=2 and date_diff('day',gps.event_timestamp,o.event_timestamp)>1 then 'day_2'\n",
    "         when date_diff('day',gps.event_timestamp,o.event_timestamp)<=3 and date_diff('day',gps.event_timestamp,o.event_timestamp)>2 then 'day_3'\n",
    "         when date_diff('day',gps.event_timestamp,o.event_timestamp)<=4 and date_diff('day',gps.event_timestamp,o.event_timestamp)>3 then 'day_4'\n",
    "         when date_diff('day',gps.event_timestamp,o.event_timestamp)<=5 and date_diff('day',gps.event_timestamp,o.event_timestamp)>4 then 'day_5'\n",
    "        else 'others'\n",
    "    end as day_flag\n",
    "\n",
    "    from output o\n",
    "    inner join single_truck_sps s on s.sp_id = o.sp_id\n",
    "    inner join gps_features_district gps on s.truck_number = gps.truck_number and o.event_timestamp>gps.event_timestamp and gps.event_timestamp>=o.event_timestamp - interval '5' day\n",
    "    inner join distict_distance d on d.from_district_id = o.district_id and d.to_district_id = gps.entity\n",
    "    ),\n",
    "\n",
    "    gps_day_level_temp as (\n",
    "    select\n",
    "    id,\n",
    "    sp_id,\n",
    "    truck_number,\n",
    "    district_id,\n",
    "    state_id,\n",
    "    event_timestamp,\n",
    "    day_flag,\n",
    "    availability_flag,\n",
    "    max(total_dwell_time) as total_dwell_time,\n",
    "    max_by(total_is_ignition_off, total_dwell_time) as total_is_ignition_off,\n",
    "    max_by(district_id_gps, total_dwell_time) as district_id_gps\n",
    "    from gps_merge_temp\n",
    "    where day_flag != 'others'\n",
    "    group by 1,2,3,4,5,6,7,8\n",
    "    ),\n",
    "\n",
    "    day_level_features as (\n",
    "    select gps.*,\n",
    "    COALESCE(d.similarity, -100) as district_similarity\n",
    "    from gps_day_level_temp gps\n",
    "    left join district_similarity d on gps.district_id = d.from_district_id and gps.district_id_gps = d.to_district_id\n",
    "    ),\n",
    "\n",
    "\n",
    "    gps_trajectory as (\n",
    "    select\n",
    "    id,\n",
    "    sp_id,\n",
    "    truck_number,\n",
    "    event_timestamp,\n",
    "    district_id, state_id,\n",
    "    availability_flag,\n",
    "    array_agg(array[cast(district_similarity as int), cast(total_dwell_time as int), cast(total_is_ignition_off as int)] order by day_flag ASC) as st_features\n",
    "    from day_level_features\n",
    "    group by 1,2,3,4,5,6,7\n",
    "    order by sp_id, event_timestamp, district_id\n",
    "    ),\n",
    "\n",
    "    gps_district_characteristics_temp as (\n",
    "    select\n",
    "    f.id,\n",
    "    f.truck_number,\n",
    "    max_by(gps_agg.total_dwell_time, gps_agg.event_timestamp) as total_dwell_time,\n",
    "    max_by(gps_agg.total_speed, gps_agg.event_timestamp) as total_speed_agg,\n",
    "    max_by(gps_agg.total_is_ignition_off, gps_agg.event_timestamp) as total_is_ignition_off_agg,\n",
    "    max_by(gps_agg.total_records, gps_agg.event_timestamp) as total_records_agg\n",
    "    from gps_merge_temp f\n",
    "    inner join gps_features_district_aggregate gps_agg on f.truck_number = gps_agg.truck_number and f.district_id = gps_agg.entity\n",
    "    and f.event_timestamp>gps_agg.event_timestamp\n",
    "    group by 1,2\n",
    "    ),\n",
    "\n",
    "    gps_district_characteristics as (\n",
    "    select\n",
    "    id,\n",
    "    ARRAY[cast(COALESCE(total_dwell_time,0) as int),\n",
    "             cast(COALESCE(total_speed_agg,0) as int),\n",
    "             cast(COALESCE(total_is_ignition_off_agg,0) as int),\n",
    "             cast(COALESCE(total_records_agg,0) as int)] as agg_features\n",
    "    from gps_district_characteristics_temp\n",
    "    )\n",
    "    select\n",
    "    o.id,o.sp_id,s.truck_number,o.event_timestamp,case when o.availability_flag = 'AVAILABLE' then 1 else 0 end as available_flag,  o.district_id,\n",
    "    gps_tj.st_features,\n",
    "    gps_agg.agg_features\n",
    "    from output o\n",
    "    inner join single_truck_sps s on s.sp_id = o.sp_id\n",
    "    inner join gps_trajectory gps_tj on gps_tj.id=o.id\n",
    "    inner join gps_district_characteristics gps_agg on gps_agg.id = o.id\n",
    "    group by 1,2,3,4,5,6,7,8\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2e3f052",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= wr.athena.read_sql_query(query, \n",
    "                                   database = config.feature_db, \n",
    "                                   workgroup = config.work_group,\n",
    "                                   s3_output = config.s3_athena_output,\n",
    "                               ctas_approach=True\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40bad3b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79680, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6eb19b1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79680"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6c26905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'sp_id', 'truck_number', 'event_timestamp', 'available_flag',\n",
       "       'district_id', 'st_features', 'agg_features'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c36fd99c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5126"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['truck_number'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "779469cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "568"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['district_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04798db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "\n",
    "with output as (\n",
    "select * from avl_training_output_v2\n",
    "),\n",
    "\n",
    "------- District Long Term Features\n",
    "sp_district_features_temp as (\n",
    "select * from avl_sp_district_lt\n",
    "),\n",
    "\n",
    "sp_district_features as (\n",
    "SELECT sp_id, event_timestamp, district_id,\n",
    "find_loads,\n",
    "indent_click,\n",
    "select_truck_type,\n",
    "book_load,\n",
    "bid,\n",
    "call,\n",
    "confirm_booking,\n",
    "search\n",
    "FROM\n",
    "(\n",
    "SELECT t.sp_id, t.event_timestamp, t.district_id,\n",
    "t.find_loads,\n",
    "t.indent_click,\n",
    "t.select_truck_type,\n",
    "t.book_load,\n",
    "t.bid,\n",
    "t.call,\n",
    "t.confirm_booking,\n",
    "t.search,\n",
    "ROW_NUMBER() OVER (PARTITION BY sp_id, district_id, event_timestamp\n",
    "              ORDER BY created_timestamp DESC) AS rnk\n",
    "FROM sp_district_features_temp t\n",
    ")\n",
    "WHERE rnk = 1\n",
    "),\n",
    "\n",
    "\n",
    "------- District Long Term Features (Max)\n",
    "sp_district_features_max_temp as (\n",
    "select * from avl_sp_district_lt_max\n",
    "),\n",
    "\n",
    "sp_district_features_max as (\n",
    "SELECT sp_id, event_timestamp,\n",
    "find_loads,\n",
    "indent_click,\n",
    "select_truck_type,\n",
    "book_load,\n",
    "bid,\n",
    "call,\n",
    "confirm_booking,\n",
    "search\n",
    "FROM\n",
    "(\n",
    "SELECT t.sp_id, t.event_timestamp,\n",
    "t.find_loads,\n",
    "t.indent_click,\n",
    "t.select_truck_type,\n",
    "t.book_load,\n",
    "t.bid,\n",
    "t.call,\n",
    "t.confirm_booking,\n",
    "t.search,\n",
    "ROW_NUMBER() OVER (PARTITION BY sp_id, event_timestamp\n",
    "              ORDER BY created_timestamp DESC) AS rnk\n",
    "FROM sp_district_features_max_temp t\n",
    ")\n",
    "WHERE rnk = 1\n",
    "),\n",
    "\n",
    "\n",
    "\n",
    "-----State Long Term Features\n",
    "sp_state_features_temp as (\n",
    "select * from avl_sp_state_lt\n",
    "),\n",
    "\n",
    "sp_state_features as (\n",
    "SELECT sp_id, event_timestamp, state_id,\n",
    "find_loads,\n",
    "indent_click,\n",
    "select_truck_type,\n",
    "book_load,\n",
    "bid,\n",
    "call,\n",
    "confirm_booking,\n",
    "search\n",
    "FROM\n",
    "(\n",
    "SELECT t.sp_id, t.event_timestamp, t.state_id,\n",
    "t.find_loads,\n",
    "t.indent_click,\n",
    "t.select_truck_type,\n",
    "t.book_load,\n",
    "t.bid,\n",
    "t.call,\n",
    "t.confirm_booking,\n",
    "t.search,\n",
    "ROW_NUMBER() OVER (PARTITION BY sp_id, state_id, event_timestamp\n",
    "              ORDER BY created_timestamp DESC) AS rnk\n",
    "FROM sp_state_features_temp t\n",
    ") \n",
    "WHERE rnk = 1\n",
    "),\n",
    "\n",
    "\n",
    "\n",
    "-----State Long Term Features (Max)\n",
    "sp_state_features_max_temp as (\n",
    "select * from avl_sp_state_lt_max\n",
    "),\n",
    "\n",
    "sp_state_features_max as (\n",
    "SELECT sp_id, event_timestamp,\n",
    "find_loads,\n",
    "indent_click,\n",
    "select_truck_type,\n",
    "book_load,\n",
    "bid,\n",
    "call,\n",
    "confirm_booking,\n",
    "search\n",
    "FROM\n",
    "(\n",
    "SELECT t.sp_id, t.event_timestamp,\n",
    "t.find_loads,\n",
    "t.indent_click,\n",
    "t.select_truck_type,\n",
    "t.book_load,\n",
    "t.bid,\n",
    "t.call,\n",
    "t.confirm_booking,\n",
    "t.search,\n",
    "ROW_NUMBER() OVER (PARTITION BY sp_id, event_timestamp\n",
    "              ORDER BY created_timestamp DESC) AS rnk\n",
    "FROM sp_state_features_max_temp t\n",
    ") \n",
    "WHERE rnk = 1\n",
    "),\n",
    "\n",
    "\n",
    "\n",
    "---- Get the latest long term features from district w.r.t output entities\n",
    "lt_features_d as (\n",
    "select id,\n",
    "find_loads,\n",
    "indent_click,\n",
    "select_truck_type,\n",
    "book_load,\n",
    "bid,\n",
    "call,\n",
    "confirm_booking,\n",
    "search\n",
    "from\n",
    "(\n",
    "select t.*,\n",
    "d.event_timestamp as event_timestamp_lt,\n",
    "d.find_loads,\n",
    "d.indent_click,\n",
    "d.select_truck_type,\n",
    "d.book_load,\n",
    "d.bid,\n",
    "d.call,\n",
    "d.confirm_booking,\n",
    "d.search,\n",
    "ROW_NUMBER() OVER (PARTITION BY t.id, t.sp_id, t.district_id, t.event_timestamp ORDER BY d.event_timestamp DESC) AS rnk\n",
    "from output t\n",
    "left join sp_district_features d on d.sp_id = t.sp_id and d.district_id = t.district_id\n",
    "where d.event_timestamp<t.event_timestamp\n",
    "order by t.sp_id, t.district_id, t.event_timestamp, d.event_timestamp\n",
    ")\n",
    "where rnk=1\n",
    "),\n",
    "\n",
    "\n",
    "\n",
    "lt_features_max_d as (\n",
    "select id,\n",
    "find_loads,\n",
    "indent_click,\n",
    "select_truck_type,\n",
    "book_load,\n",
    "bid,\n",
    "call,\n",
    "confirm_booking,\n",
    "search\n",
    "from\n",
    "(\n",
    "select t.*,\n",
    "d.event_timestamp as event_timestamp_lt,\n",
    "d.find_loads,\n",
    "d.indent_click,\n",
    "d.select_truck_type,\n",
    "d.book_load,\n",
    "d.bid,\n",
    "d.call,\n",
    "d.confirm_booking,\n",
    "d.search,\n",
    "ROW_NUMBER() OVER (PARTITION BY t.id, t.sp_id, t.event_timestamp ORDER BY d.event_timestamp DESC) AS rnk\n",
    "from output t\n",
    "left join sp_district_features_max d on d.sp_id = t.sp_id\n",
    "where d.event_timestamp<t.event_timestamp\n",
    ")\n",
    "where rnk=1\n",
    "),\n",
    "\n",
    "\n",
    "\n",
    "---- Get the latest long term features from state w.r.t output entities\n",
    "\n",
    "lt_features_s as (\n",
    "select id,\n",
    "find_loads,\n",
    "indent_click,\n",
    "select_truck_type,\n",
    "book_load,\n",
    "bid,\n",
    "call,\n",
    "confirm_booking,\n",
    "search\n",
    "from\n",
    "(\n",
    "select t.*,\n",
    "d.event_timestamp as event_timestamp_lt,\n",
    "d.find_loads,\n",
    "d.indent_click,\n",
    "d.select_truck_type,\n",
    "d.book_load,\n",
    "d.bid,\n",
    "d.call,\n",
    "d.confirm_booking,\n",
    "d.search,\n",
    "ROW_NUMBER() OVER (PARTITION BY t.id, t.sp_id, t.state_id, t.event_timestamp ORDER BY d.event_timestamp DESC) AS rnk\n",
    "from output t\n",
    "left join sp_state_features d on d.sp_id = t.sp_id and d.state_id = t.state_id\n",
    "where d.event_timestamp<t.event_timestamp\n",
    "order by t.sp_id, t.state_id, t.event_timestamp, d.event_timestamp\n",
    ")\n",
    "where rnk=1\n",
    "),\n",
    "\n",
    "\n",
    "lt_features_max_s as (\n",
    "select id,\n",
    "find_loads,\n",
    "indent_click,\n",
    "select_truck_type,\n",
    "book_load,\n",
    "bid,\n",
    "call,\n",
    "confirm_booking,\n",
    "search\n",
    "from\n",
    "(\n",
    "select t.id,\n",
    "d.event_timestamp as event_timestamp_lt,\n",
    "d.find_loads,\n",
    "d.indent_click,\n",
    "d.select_truck_type,\n",
    "d.book_load,\n",
    "d.bid,\n",
    "d.call,\n",
    "d.confirm_booking,\n",
    "d.search,\n",
    "ROW_NUMBER() OVER (PARTITION BY t.id, t.sp_id, t.event_timestamp ORDER BY d.event_timestamp DESC) AS rnk\n",
    "from output t\n",
    "left join sp_state_features_max d on d.sp_id = t.sp_id\n",
    "where d.event_timestamp<t.event_timestamp\n",
    ")\n",
    "where rnk=1\n",
    "),\n",
    "\n",
    "----- Joining Features\n",
    "lt_features as (\n",
    "select \n",
    "t.*,\n",
    "\n",
    "coalesce(fd.find_loads, 0) as find_loads_d,\n",
    "coalesce(fd.indent_click, 0) as indent_click_d,\n",
    "coalesce(fd.select_truck_type, 0) as select_truck_type_d,\n",
    "coalesce(fd.book_load, 0) as book_load_d,\n",
    "coalesce(fd.bid, 0) as bid_d,\n",
    "coalesce(fd.call, 0) as call_d,\n",
    "coalesce(fd.confirm_booking, 0) as confirm_booking_d,\n",
    "coalesce(fd.search, 0) as search_d,\n",
    "\n",
    "coalesce(fs.find_loads, 0) as find_loads_s,\n",
    "coalesce(fs.indent_click, 0) as indent_click_s,\n",
    "coalesce(fs.select_truck_type, 0) as select_truck_type_s,\n",
    "coalesce(fs.book_load, 0) as book_load_s,\n",
    "coalesce(fs.bid, 0) as bid_s,\n",
    "coalesce(fs.call, 0) as call_s,\n",
    "coalesce(fs.confirm_booking, 0) as confirm_booking_s,\n",
    "coalesce(fs.search, 0) as search_s,\n",
    "\n",
    "coalesce(fmd.find_loads, 0) as find_loads_d_max,\n",
    "coalesce(fmd.indent_click, 0) as indent_click_d_max,\n",
    "coalesce(fmd.select_truck_type, 0) as select_truck_type_d_max,\n",
    "coalesce(fmd.book_load, 0) as book_load_d_max,\n",
    "coalesce(fmd.bid, 0) as bid_d_max,\n",
    "coalesce(fmd.call, 0) as call_d_max,\n",
    "coalesce(fmd.confirm_booking, 0) as confirm_booking_d_max,\n",
    "coalesce(fmd.search, 0) as search_d_max,\n",
    "\n",
    "coalesce(fms.find_loads, 0) as find_loads_s_max,\n",
    "coalesce(fms.indent_click, 0) as indent_click_s_max,\n",
    "coalesce(fms.select_truck_type, 0) as select_truck_type_s_max,\n",
    "coalesce(fms.book_load, 0) as book_load_s_max,\n",
    "coalesce(fms.bid, 0) as bid_s_max,\n",
    "coalesce(fms.call, 0) as call_s_max,\n",
    "coalesce(fms.confirm_booking, 0) as confirm_booking_s_max,\n",
    "coalesce(fms.search, 0) as search_s_max\n",
    "\n",
    "from output t\n",
    "left join lt_features_d fd on fd.id = t.id\n",
    "left join lt_features_s fs on fs.id = t.id\n",
    "\n",
    "left join lt_features_max_d fmd on fmd.id = t.id\n",
    "left join lt_features_max_s fms on fms.id = t.id\n",
    ")\n",
    "\n",
    "select\n",
    "id, sp_id, event_timestamp, district_id, state_id, availability_flag,\n",
    "ARRAY[\n",
    "cast(COALESCE(1000*find_loads_d/NULLIF(find_loads_d_max,0), 0) as int),\n",
    "cast(COALESCE(1000*indent_click_d/NULLIF(indent_click_d_max,0), 0) as int),\n",
    "cast(COALESCE(1000*select_truck_type_d/NULLIF(select_truck_type_d_max,0), 0) as int),\n",
    "cast(COALESCE(1000*book_load_d/NULLIF(book_load_d_max,0), 0) as int),\n",
    "cast(COALESCE(1000*bid_d/NULLIF(bid_d_max,0), 0) as int),\n",
    "cast(COALESCE(1000*call_d/NULLIF(call_d_max,0), 0) as int),\n",
    "cast(COALESCE(1000*confirm_booking_d/NULLIF(confirm_booking_d_max,0), 0) as int),\n",
    "cast(COALESCE(1000*search_d/NULLIF(search_d_max,0), 0) as int),\n",
    "cast(COALESCE(1000*find_loads_s/NULLIF(find_loads_s_max,0), 0) as int),\n",
    "cast(COALESCE(1000*indent_click_s/NULLIF(indent_click_s_max,0), 0) as int),\n",
    "cast(COALESCE(1000*select_truck_type_s/NULLIF(select_truck_type_s_max,0), 0) as int),\n",
    "cast(COALESCE(1000*book_load_s/NULLIF(book_load_s_max,0), 0) as int),\n",
    "cast(COALESCE(1000*bid_s/NULLIF(bid_s_max,0), 0) as int),\n",
    "cast(COALESCE(1000*call_s/NULLIF(call_s_max,0), 0) as int),\n",
    "cast(COALESCE(1000*confirm_booking_s/NULLIF(confirm_booking_s_max,0), 0) as int),\n",
    "cast(COALESCE(1000*search_s/NULLIF(search_s_max,0), 0) as int)\n",
    "] as lt_features\n",
    "from lt_features\n",
    "where\n",
    "(find_loads_d+indent_click_d+select_truck_type_d+book_load_d+bid_d+call_d+confirm_booking_d+search_d+\n",
    "find_loads_s+indent_click_s+select_truck_type_s+book_load_s+bid_s+call_s+confirm_booking_s+search_s)>0\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53aba6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_term_features = wr.athena.read_sql_query(query, \n",
    "                                   database = config.feature_db, \n",
    "                                   workgroup = config.work_group,\n",
    "                                   s3_output = config.s3_athena_output\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f2f784d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'sp_id', 'event_timestamp', 'district_id', 'state_id',\n",
       "       'availability_flag', 'lt_features'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_term_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6e21db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.merge(df, long_term_features[['id', 'lt_features']], how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1890eb60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78229, 9)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7379b321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sp_id</th>\n",
       "      <th>truck_number</th>\n",
       "      <th>event_timestamp</th>\n",
       "      <th>available_flag</th>\n",
       "      <th>district_id</th>\n",
       "      <th>st_features</th>\n",
       "      <th>agg_features</th>\n",
       "      <th>lt_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1635143</td>\n",
       "      <td>3439775</td>\n",
       "      <td>MH19CY7144</td>\n",
       "      <td>2021-10-07 12:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>aa681238551556378624</td>\n",
       "      <td>[[-2, 1695, 332], [-2, 1017, 247], [-2, 83, 75]]</td>\n",
       "      <td>[670, 41941, 619, 1682]</td>\n",
       "      <td>[1000, 1000, 1000, 1000, 0, 1000, 1000, 1000, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1232026</td>\n",
       "      <td>1148410</td>\n",
       "      <td>UP75AT5491</td>\n",
       "      <td>2021-05-19 12:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>aa681238548536479744</td>\n",
       "      <td>[[-11, 3438, 1186], [100, 781, 221], [100, 449...</td>\n",
       "      <td>[960, 66157, 251, 1922]</td>\n",
       "      <td>[7, 28, 13, 0, 0, 0, 0, 18, 76, 226, 211, 500,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id    sp_id truck_number     event_timestamp  available_flag  \\\n",
       "0  1635143  3439775   MH19CY7144 2021-10-07 12:00:00               0   \n",
       "1  1232026  1148410   UP75AT5491 2021-05-19 12:00:00               0   \n",
       "\n",
       "            district_id                                        st_features  \\\n",
       "0  aa681238551556378624   [[-2, 1695, 332], [-2, 1017, 247], [-2, 83, 75]]   \n",
       "1  aa681238548536479744  [[-11, 3438, 1186], [100, 781, 221], [100, 449...   \n",
       "\n",
       "              agg_features                                        lt_features  \n",
       "0  [670, 41941, 619, 1682]  [1000, 1000, 1000, 1000, 0, 1000, 1000, 1000, ...  \n",
       "1  [960, 66157, 251, 1922]  [7, 28, 13, 0, 0, 0, 0, 18, 76, 226, 211, 500,...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c43695b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data['available_flag'] = training_data['availability_flag'].apply(lambda x: 1 if x == 'AVAILABLE' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d112c7d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sp_id</th>\n",
       "      <th>truck_number</th>\n",
       "      <th>event_timestamp</th>\n",
       "      <th>available_flag</th>\n",
       "      <th>district_id</th>\n",
       "      <th>st_features</th>\n",
       "      <th>agg_features</th>\n",
       "      <th>lt_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1635143</td>\n",
       "      <td>3439775</td>\n",
       "      <td>MH19CY7144</td>\n",
       "      <td>2021-10-07 12:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>aa681238551556378624</td>\n",
       "      <td>[[-2, 1695, 332], [-2, 1017, 247], [-2, 83, 75]]</td>\n",
       "      <td>[670, 41941, 619, 1682]</td>\n",
       "      <td>[1000, 1000, 1000, 1000, 0, 1000, 1000, 1000, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id    sp_id truck_number     event_timestamp  available_flag  \\\n",
       "0  1635143  3439775   MH19CY7144 2021-10-07 12:00:00               0   \n",
       "\n",
       "            district_id                                       st_features  \\\n",
       "0  aa681238551556378624  [[-2, 1695, 332], [-2, 1017, 247], [-2, 83, 75]]   \n",
       "\n",
       "              agg_features                                        lt_features  \n",
       "0  [670, 41941, 619, 1682]  [1000, 1000, 1000, 1000, 0, 1000, 1000, 1000, ...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d30195c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data = training_data[training_data['agg_features'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a68d3e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78229, 9)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df73cd30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78229"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5cb37706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4977"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['truck_number'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d163e6ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "566"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['district_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6c43b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'sp_id', 'truck_number', 'event_timestamp', 'available_flag',\n",
       "       'district_id', 'st_features', 'agg_features'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5c07484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[['st_features','available_flag']].to_csv('avail_manifest_v0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3077566",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers import LSTM, Dropout, Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import LSTM,Attention\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Embedding,Reshape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "08ae6465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'sp_id', 'truck_number', 'event_timestamp', 'available_flag',\n",
       "       'district_id', 'st_features', 'agg_features', 'lt_features'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c0b6478c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sp_id</th>\n",
       "      <th>truck_number</th>\n",
       "      <th>event_timestamp</th>\n",
       "      <th>available_flag</th>\n",
       "      <th>district_id</th>\n",
       "      <th>st_features</th>\n",
       "      <th>agg_features</th>\n",
       "      <th>lt_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1635143</td>\n",
       "      <td>3439775</td>\n",
       "      <td>MH19CY7144</td>\n",
       "      <td>2021-10-07 12:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>aa681238551556378624</td>\n",
       "      <td>[[-2, 1695, 332], [-2, 1017, 247], [-2, 83, 75]]</td>\n",
       "      <td>[670, 41941, 619, 1682]</td>\n",
       "      <td>[1000, 1000, 1000, 1000, 0, 1000, 1000, 1000, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1232026</td>\n",
       "      <td>1148410</td>\n",
       "      <td>UP75AT5491</td>\n",
       "      <td>2021-05-19 12:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>aa681238548536479744</td>\n",
       "      <td>[[-11, 3438, 1186], [100, 781, 221], [100, 449...</td>\n",
       "      <td>[960, 66157, 251, 1922]</td>\n",
       "      <td>[7, 28, 13, 0, 0, 0, 0, 18, 76, 226, 211, 500,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id    sp_id truck_number     event_timestamp  available_flag  \\\n",
       "0  1635143  3439775   MH19CY7144 2021-10-07 12:00:00               0   \n",
       "1  1232026  1148410   UP75AT5491 2021-05-19 12:00:00               0   \n",
       "\n",
       "            district_id                                        st_features  \\\n",
       "0  aa681238551556378624   [[-2, 1695, 332], [-2, 1017, 247], [-2, 83, 75]]   \n",
       "1  aa681238548536479744  [[-11, 3438, 1186], [100, 781, 221], [100, 449...   \n",
       "\n",
       "              agg_features                                        lt_features  \n",
       "0  [670, 41941, 619, 1682]  [1000, 1000, 1000, 1000, 0, 1000, 1000, 1000, ...  \n",
       "1  [960, 66157, 251, 1922]  [7, 28, 13, 0, 0, 0, 0, 18, 76, 226, 211, 500,...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fe157791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([  -2, 1695,  332], dtype=int32),\n",
       "       array([  -2, 1017,  247], dtype=int32),\n",
       "       array([-2, 83, 75], dtype=int32)], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['st_features'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "19362fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78229, 9)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d606477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "output = np.array(training_data.available_flag.to_list())\n",
    "output = tf.convert_to_tensor(output, np.int8)\n",
    "\n",
    "### LSTM Features\n",
    "st_features = []\n",
    "for i in training_data.st_features.to_list():\n",
    "    i = i.tolist()\n",
    "    k = []\n",
    "    for j in i:\n",
    "        k.append(j.tolist())\n",
    "    st_features.append(k)\n",
    "\n",
    "st_features = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    st_features, maxlen=5,padding=\"post\"\n",
    ")\n",
    "\n",
    "st_features = tf.convert_to_tensor(st_features, np.int8)\n",
    "\n",
    "\n",
    "### Long Term Features\n",
    "lt_features = []\n",
    "for i in training_data.lt_features.to_list():\n",
    "    i = i.tolist()\n",
    "    lt_features.append(i)\n",
    "    \n",
    "lt_features = tf.convert_to_tensor(lt_features, np.int8)\n",
    "\n",
    "## agg features\n",
    "\n",
    "\n",
    "\n",
    "agg_features = []\n",
    "for i in training_data.agg_features.to_list():\n",
    "    i = i.tolist()\n",
    "    agg_features.append(i)\n",
    "    \n",
    "agg_features = tf.convert_to_tensor(agg_features, np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e0f291e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gps_characteristics = []\n",
    "\n",
    "# for i in range(len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "27748567",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def Find_Optimal_Cutoff(target, predicted):\n",
    "    fpr, tpr, threshold = roc_curve(target, predicted)\n",
    "    i = np.arange(len(tpr)) \n",
    "    roc = pd.DataFrame({'tf' : pd.Series(tpr-(1-fpr), index=i), 'threshold' : pd.Series(threshold, index=i)})\n",
    "    roc_t = roc.iloc[(roc.tf-0).abs().argsort()[:1]]\n",
    "\n",
    "    return list(roc_t['threshold']) \n",
    "\n",
    "class prediction_history(Callback):\n",
    "    def __init__(self):\n",
    "        self.predhis = []\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.predhis.append(model.predict([x_test]))\n",
    "\n",
    "predictions=prediction_history()\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=4, min_delta=0)\n",
    "bst_model_path =  'truck_availability_attn_model_tf.h5'\n",
    "model_checkpoint = ModelCheckpoint(bst_model_path, save_best_only=True, save_weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "076e2ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timesteps = st_features.shape[1]\n",
    "n_features = st_features.shape[2]\n",
    "n_lt_features = lt_features.shape[1]\n",
    "n_agg_features = agg_features.shape[1]\n",
    "# n_agg_features = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8f97394e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((79680, 8), (3956015, 7))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape,long_term_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "473f428b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "class attention(Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(attention,self).__init__(**kwargs)\n",
    "\n",
    "    def build(self,input_shape):\n",
    "        self.W=self.add_weight(name=\"att_weight\",shape=(input_shape[-1],1),initializer=\"normal\")\n",
    "        self.b=self.add_weight(name=\"att_bias\",shape=(input_shape[1],1),initializer=\"zeros\")        \n",
    "        super(attention, self).build(input_shape)\n",
    "\n",
    "    def call(self,x):\n",
    "        et=K.squeeze(K.tanh(K.dot(x,self.W)+self.b),axis=-1)\n",
    "        at=K.softmax(et)\n",
    "        at=K.expand_dims(at,axis=-1)\n",
    "        output=x*at\n",
    "        return K.sum(output,axis=1)\n",
    "\n",
    "    def compute_output_shape(self,input_shape):\n",
    "        return (input_shape[0],input_shape[-1])\n",
    "\n",
    "    def get_config(self):\n",
    "        return super(attention,self).get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "323df044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 5, 3)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 5, 200)       163200      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (attention)           (None, 200)          205         lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 200)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 16)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 220)          0           dropout[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          56576       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          32896       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           8256        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            65          dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 261,198\n",
      "Trainable params: 261,198\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ts_input = Input(shape=(n_timesteps,n_features))\n",
    "main_input_lstm = LSTM(200, activation='relu',return_sequences=True)(ts_input)\n",
    "attn_input = attention()(main_input_lstm)\n",
    "st_input = Dropout(0.5)(attn_input)\n",
    "\n",
    "lt_input = Input(shape=(n_lt_features,))\n",
    "agg_input = Input(shape=(n_agg_features,))\n",
    "merged = tf.keras.layers.Concatenate(axis=1)([st_input, lt_input,agg_input])\n",
    "\n",
    "\n",
    "x = Dense(256, activation='relu')(merged)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "main_output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=[ts_input,lt_input,agg_input], outputs= [main_output])\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1f10258e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78229, 9)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dd32358e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78229"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b1272d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(st_features, output, \n",
    "#           epochs=30,  batch_size=1024, \n",
    "#           verbose = True, validation_split=0.2,\n",
    "#           callbacks=[model_checkpoint, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c8e4b883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd57178",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1aa4c714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_input = Input(shape=(n_timesteps,n_features))\n",
    "# main_input_lstm = LSTM(200, activation='relu')(ts_input)\n",
    "# st_input = Dropout(0.5)(main_input_lstm)\n",
    "\n",
    "# lt_input = Input(shape=(n_lt_features,))\n",
    "\n",
    "# merged = tf.keras.layers.Concatenate(axis=1)([st_input, lt_input])\n",
    "\n",
    "# x = Dense(256, activation='relu')(merged)\n",
    "# x = Dense(128, activation='relu')(x)\n",
    "# x = Dense(64, activation='relu')(x)\n",
    "# main_output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# model = Model(inputs=[ts_input, lt_input], outputs= [main_output])\n",
    "\n",
    "# model.compile(optimizer=Adam(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d4664fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-16 11:27:23.167 ip-172-16-43-13:25309 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2022-02-16 11:27:23.301 ip-172-16-43-13:25309 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "Train on 58671 samples, validate on 19558 samples\n",
      "Epoch 1/50\n",
      "58671/58671 [==============================] - 11s 196us/sample - loss: 0.9279 - accuracy: 0.5969 - val_loss: 0.6912 - val_accuracy: 0.6450\n",
      "Epoch 2/50\n",
      "58671/58671 [==============================] - 9s 148us/sample - loss: 0.6393 - accuracy: 0.6658 - val_loss: 0.6318 - val_accuracy: 0.6648\n",
      "Epoch 3/50\n",
      "58671/58671 [==============================] - 9s 146us/sample - loss: 0.6015 - accuracy: 0.6894 - val_loss: 0.6222 - val_accuracy: 0.6691\n",
      "Epoch 4/50\n",
      "58671/58671 [==============================] - 9s 146us/sample - loss: 0.5823 - accuracy: 0.7013 - val_loss: 0.6152 - val_accuracy: 0.6788\n",
      "Epoch 5/50\n",
      "58671/58671 [==============================] - 9s 146us/sample - loss: 0.5693 - accuracy: 0.7106 - val_loss: 0.6167 - val_accuracy: 0.6782\n",
      "Epoch 6/50\n",
      "58671/58671 [==============================] - 9s 147us/sample - loss: 0.5590 - accuracy: 0.7171 - val_loss: 0.6145 - val_accuracy: 0.6845\n",
      "Epoch 7/50\n",
      "58671/58671 [==============================] - 9s 157us/sample - loss: 0.5446 - accuracy: 0.7268 - val_loss: 0.6094 - val_accuracy: 0.6814\n",
      "Epoch 8/50\n",
      "58671/58671 [==============================] - 9s 145us/sample - loss: 0.5349 - accuracy: 0.7332 - val_loss: 0.6088 - val_accuracy: 0.6827\n",
      "Epoch 9/50\n",
      "58671/58671 [==============================] - 9s 145us/sample - loss: 0.5263 - accuracy: 0.7387 - val_loss: 0.6095 - val_accuracy: 0.6850\n",
      "Epoch 10/50\n",
      "58671/58671 [==============================] - 8s 145us/sample - loss: 0.5148 - accuracy: 0.7468 - val_loss: 0.6162 - val_accuracy: 0.6851\n",
      "Epoch 11/50\n",
      "58671/58671 [==============================] - 9s 145us/sample - loss: 0.5050 - accuracy: 0.7519 - val_loss: 0.6192 - val_accuracy: 0.6865\n",
      "Epoch 12/50\n",
      "58671/58671 [==============================] - 9s 145us/sample - loss: 0.4940 - accuracy: 0.7600 - val_loss: 0.6199 - val_accuracy: 0.6879\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdec946a7f0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([st_features, lt_features,agg_features], output, \n",
    "          epochs=50,  batch_size=1024, \n",
    "          verbose = True, validation_split=0.25,\n",
    "          callbacks=[model_checkpoint, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd12f88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['sp_id']==3178051].to_csv('one_sp_val_sample.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "617be37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(features_list),len(features_list[0]),len(features_list[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e6181b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2143a53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_list = np.array(sequences_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ce677dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20337*25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7f273d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_list = np.reshape(features_list,( features_list.shape[0],features_list.shape[1],4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e9a25e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_list=np.array(features_list).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f7028809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# tf.convert_to_tensor(features_list, dtype=tf.int32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6a7b67cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (features_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1dae942c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit([features_list[:int(len(features_list)*.8)]], output[:int(len(features_list)*.8)], epochs=10,batch_size=10,\n",
    "#           validation_data = ([features_list[int(len(features_list)*.8):]], output[int(len(features_list)*.8):]),\n",
    "#           verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbafee7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
