{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b92fe5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dateutil.tz\n",
    "import datetime as dt\n",
    "import json\n",
    "import awswrangler as wr\n",
    "from feature_store import feature_store\n",
    "from feature_store.feature_table import feature_table\n",
    "from feature_store.value_type import ValueType\n",
    "import feature_store.config as config\n",
    "from io import StringIO\n",
    "import urllib3\n",
    "import logging\n",
    "import sys\n",
    "from json import dumps\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "def get_ymd(datetime):\n",
    "    year = datetime.year\n",
    "    month = datetime.month\n",
    "    day = datetime.day\n",
    "            \n",
    "    if month < 10:\n",
    "        month = '0' + str(month)\n",
    "    if day < 10:\n",
    "        day = '0' + str(day)\n",
    "    return year, month, day\n",
    "\n",
    "def first_day_next_month(date):\n",
    "    return (date.replace(day=1) + dt.timedelta(days=32)).replace(day=1)\n",
    "\n",
    "def last_second_of_month(date: str) -> str:\n",
    "    return str((pd.Timestamp(date) + pd.offsets.MonthEnd(0)).date()) + \" 23:59:59\"\n",
    "\n",
    "def first_second_of_month(date: str) -> str:\n",
    "    return str((pd.Timestamp(date) + pd.offsets.MonthBegin(0)).date()) + \" 00:00:00\"\n",
    "\n",
    "streamer = StringIO()\n",
    "\n",
    "def setup_logging():\n",
    "    logger = logging.getLogger()\n",
    "    for h in logger.handlers:\n",
    "        logger.removeHandler(h)\n",
    "     \n",
    "    h = logging.StreamHandler(stream = streamer)\n",
    "    h.setFormatter(logging.Formatter(\"%(asctime)s %(levelname)s: %(message)s\",\n",
    "                              \"%Y-%m-%d %H:%M:%S\"))\n",
    "    logger.addHandler(h)\n",
    "    logger.setLevel(logging.INFO)\n",
    "    return logger\n",
    "\n",
    "def query_log(query_id, table, logger):\n",
    "    status = wr.athena.get_query_execution(query_id)['Status']['State']\n",
    "    if wr.athena.get_query_execution(query_id)['Status']['State'] in ['FAILED', 'CANCELLED']:\n",
    "        logger.critical(table + ': query is in ' + status + ' State. ' + 'QueryID: ' + query_id)\n",
    "    else:\n",
    "        logger.info(table + ': query is in ' + status + ' State. ' + 'QueryID: ' + query_id)\n",
    "    return None\n",
    "\n",
    "http = urllib3.PoolManager()\n",
    "url = 'https://chat.googleapis.com/v1/spaces/AAAALuxU48o/messages?key=AIzaSyDdI0hCZtE6vySjMm-WEfRq3CPzqKqqsHI&token=T1j8SVrn051V2f9q0wxFMbbI5DkIH2IKTxPYy3TnP9Q%3D'\n",
    "fs = feature_store.feature_store()\n",
    "\n",
    "zone = dateutil.tz.gettz('Asia/Calcutta')\n",
    "\n",
    "logger = setup_logging()\n",
    "\n",
    "now = dt.datetime.now(zone)\n",
    "current_hour = now.replace(minute=0, second=0, microsecond=0)\n",
    "current_hour_s = current_hour.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "def query_progress(query_id, run_async, table_name):\n",
    "    if not run_async:\n",
    "            status = wr.athena.get_query_execution(query_id)['Status']['State']\n",
    "            while status not in ('SUCCEEDED'):\n",
    "                if status in ['RUNNING', 'QUEUED']:\n",
    "                    status = wr.athena.get_query_execution(query_id)['Status']['State']\n",
    "                elif status == 'FAILED':\n",
    "                    print('Query Failed')\n",
    "                    break\n",
    "                elif status == 'CANCELLED':\n",
    "                    print('Query Cancelled')\n",
    "                    break\n",
    "    else:\n",
    "        status = wr.athena.get_query_execution(query_id)['Status']['State']\n",
    "        while status not in ('RUNNING'):\n",
    "            if status == 'QUEUED':\n",
    "                time.sleep(2)\n",
    "                status = wr.athena.get_query_execution(query_id)['Status']['State']\n",
    "            elif status == 'SUCCEEDED':\n",
    "                print('Query Succeeded')\n",
    "                break\n",
    "            elif status == 'FAILED':\n",
    "                print('Query Failed')\n",
    "                break\n",
    "            elif status == 'CANCELLED':\n",
    "                print('Query Cancelled')\n",
    "                break\n",
    "    query_log(query_id, table_name, logger)\n",
    "    return status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6cbb3201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "#\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec977313",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_query='''\n",
    "select * from gps_features \n",
    "limit 10\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40b0f8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_features = wr.athena.read_sql_query(features_query, \n",
    "#                                    database = config.feature_db, \n",
    "#                                    workgroup = config.work_group,\n",
    "#                                    s3_output = config.s3_athena_output\n",
    "#                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91dbd350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_features.head(2)\n",
    "# inner join two table (where eventy_ttimestamp is in a windows of 5 day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f33a86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea713b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "query='''\n",
    "with sp_mapping_temp as (\n",
    "SELECT  id as fleet_owner_id, max_by(cast(phone_no as varchar), updated_at) as mobile_no,\n",
    "max_by(cast(iam_id as int), updated_at) as sp_id  FROM  \"awsdatacatalog\".\"supply_team\".\"supply_team_blackbuck_fleetapp_fleetowner\"\n",
    "group by 1\n",
    "),\n",
    "\n",
    "sp_mapping as (\n",
    "select fleet_owner_id, mobile_no, cast(sp_id as bigint) as sp_id \n",
    "from sp_mapping_temp \n",
    "where mobile_no in (\n",
    "select mobile_no from (\n",
    "select mobile_no, count(*) as sp_count from sp_mapping_temp\n",
    "group by 1\n",
    "having count(*)<=1))\n",
    "),\n",
    "\n",
    "--- Truck Mapping to SP ID\n",
    "truck_mapping as (\n",
    "select ft.id as truck_id,\n",
    "ft.truck_no as truck_number,\n",
    "tor.fleet_owner_id as fleet_owner_id,\n",
    "s.sp_id\n",
    "from \"awsdatacatalog\".\"supply_team\".\"supply_team_blackbuck_fleetapp_truck\" ft\n",
    "inner join \"awsdatacatalog\".\"supply_team\".\"supply_team_blackbuck_truck_owner_request\" tor on ft.id = tor.truck_id\n",
    "inner join sp_mapping s on s.fleet_owner_id = tor.fleet_owner_id\n",
    "where \n",
    "ft.truck_no != ''\n",
    "and tor.fleet_owner_id is not null\n",
    "and tor.kyc_status_v2 ='APPROVED'\n",
    "and ft.is_truck = 'VERIFIED'\n",
    "and ft.is_verified != 3\n",
    "group by 1,2,3,4\n",
    "),\n",
    "\n",
    "--- Single Truck FOs/SPs\n",
    "single_truck_sps as (\n",
    "select\n",
    "tm.*,\n",
    "tmc.number_of_trucks\n",
    "from truck_mapping tm\n",
    "left join (select sp_id, count(distinct truck_number) as number_of_trucks from truck_mapping group by 1) tmc on tmc.sp_id = tm.sp_id\n",
    "where tmc.number_of_trucks = 1\n",
    "),\n",
    "\n",
    "------ Plaza to District Mapping\n",
    "district_boundaries as (\n",
    "select place_id as district_id, \n",
    "name as district_name, \n",
    "ST_GeomFromBinary(from_hex(to_utf8(replace(boundary_geog,'20E61000')))) as boundary_geog,\n",
    "ST_X(ST_Centroid(ST_GeomFromBinary(from_hex(to_utf8(replace(boundary_geog,'20E61000')))))) as longitude,\n",
    "ST_Y(ST_Centroid(ST_GeomFromBinary(from_hex(to_utf8(replace(boundary_geog,'20E61000')))))) as latitude\n",
    "from location_service.public.admin_area where deleted = false\n",
    "and local_tag = 'DISTRICT'\n",
    "and boundary_geog != ''\n",
    "),\n",
    "\n",
    "distict_distance as (\n",
    "select a.district_id as from_district_id,\n",
    "b.district_id as to_district_id,\n",
    "cast(great_circle_distance(a.latitude, a.longitude, b.latitude, b.longitude) as int) as distance\n",
    "from district_boundaries a\n",
    "cross join district_boundaries b\n",
    "),\n",
    "\n",
    "---- Semantics District Vectors\n",
    "semantics_score_district_temp as (\n",
    "\tSELECT *\n",
    "\tFROM (\n",
    "\t\t\tSELECT t.*,\n",
    "\t\t\t\tROW_NUMBER() OVER (\n",
    "\t\t\t\t\tPARTITION BY bb_place_id\n",
    "\t\t\t\t\tORDER BY created_timestamp DESC\n",
    "\t\t\t\t) AS rnk\n",
    "\t\t\tFROM \"awsdatacatalog\".\"feature_store\".\"semantics_from_district\" t\n",
    "\t\t)\n",
    "\tWHERE rnk = 1\n",
    "),\n",
    "\n",
    "semantics_score_district_map as (\n",
    "\tselect bb_place_id as district_id,\n",
    "\t\tMAP_FROM_ENTRIES(\n",
    "\t\t\tARRAY [ ('f_1', f_1),\n",
    "\t\t\t('f_2', f_2),\n",
    "\t\t\t('f_3', f_3),\n",
    "\t\t\t('f_4', f_4),\n",
    "\t\t\t('f_5', f_5),\n",
    "\t\t\t('f_6', f_6),\n",
    "\t\t\t('f_7', f_7),\n",
    "\t\t\t('f_8', f_8),\n",
    "\t\t\t('f_9', f_9),\n",
    "\t\t\t('f_10', f_10),\n",
    "\t\t\t('f_11', f_11),\n",
    "\t\t\t('f_12', f_12),\n",
    "\t\t\t('f_13', f_13),\n",
    "\t\t\t('f_14', f_14),\n",
    "\t\t\t('f_15', f_15),\n",
    "\t\t\t('f_16', f_16),\n",
    "\t\t\t('f_17', f_17),\n",
    "\t\t\t('f_18', f_18),\n",
    "\t\t\t('f_19', f_19),\n",
    "\t\t\t('f_20', f_20),\n",
    "\t\t\t('f_21', f_21),\n",
    "\t\t\t('f_22', f_22),\n",
    "\t\t\t('f_23', f_23),\n",
    "\t\t\t('f_24', f_24),\n",
    "\t\t\t('f_25', f_25),\n",
    "\t\t\t('f_26', f_26),\n",
    "\t\t\t('f_27', f_27),\n",
    "\t\t\t('f_28', f_28),\n",
    "\t\t\t('f_29', f_29),\n",
    "\t\t\t('f_30', f_30),\n",
    "\t\t\t('f_31', f_31),\n",
    "\t\t\t('f_32', f_32),\n",
    "\t\t\t('f_33', f_33),\n",
    "\t\t\t('f_34', f_34),\n",
    "\t\t\t('f_35', f_35),\n",
    "\t\t\t('f_36', f_36),\n",
    "\t\t\t('f_37', f_37),\n",
    "\t\t\t('f_38', f_38),\n",
    "\t\t\t('f_39', f_39),\n",
    "\t\t\t('f_40', f_40),\n",
    "\t\t\t('f_41', f_41),\n",
    "\t\t\t('f_42', f_42),\n",
    "\t\t\t('f_43', f_43),\n",
    "\t\t\t('f_44', f_44),\n",
    "\t\t\t('f_45', f_45),\n",
    "\t\t\t('f_46', f_46),\n",
    "\t\t\t('f_47', f_47),\n",
    "\t\t\t('f_48', f_48),\n",
    "\t\t\t('f_49', f_49),\n",
    "\t\t\t('f_50', f_50),\n",
    "\t\t\t('f_51', f_51),\n",
    "\t\t\t('f_52', f_52),\n",
    "\t\t\t('f_53', f_53),\n",
    "\t\t\t('f_54', f_54),\n",
    "\t\t\t('f_55', f_55),\n",
    "\t\t\t('f_56', f_56),\n",
    "\t\t\t('f_57', f_57),\n",
    "\t\t\t('f_58', f_58),\n",
    "\t\t\t('f_59', f_59),\n",
    "\t\t\t('f_60', f_60),\n",
    "\t\t\t('f_61', f_61),\n",
    "\t\t\t('f_62', f_62),\n",
    "\t\t\t('f_63', f_63),\n",
    "\t\t\t('f_64', f_64),\n",
    "\t\t\t('f_65', f_65),\n",
    "\t\t\t('f_66', f_66),\n",
    "\t\t\t('f_67', f_67),\n",
    "\t\t\t('f_68', f_68),\n",
    "\t\t\t('f_69', f_69),\n",
    "\t\t\t('f_70', f_70),\n",
    "\t\t\t('f_71', f_71),\n",
    "\t\t\t('f_72', f_72),\n",
    "\t\t\t('f_73', f_73),\n",
    "\t\t\t('f_74', f_74),\n",
    "\t\t\t('f_75', f_75),\n",
    "\t\t\t('f_76', f_76),\n",
    "\t\t\t('f_77', f_77),\n",
    "\t\t\t('f_78', f_78),\n",
    "\t\t\t('f_79', f_79),\n",
    "\t\t\t('f_80', f_80),\n",
    "\t\t\t('f_81', f_81),\n",
    "\t\t\t('f_82', f_82),\n",
    "\t\t\t('f_83', f_83),\n",
    "\t\t\t('f_84', f_84),\n",
    "\t\t\t('f_85', f_85),\n",
    "\t\t\t('f_86', f_86),\n",
    "\t\t\t('f_87', f_87),\n",
    "\t\t\t('f_88', f_88),\n",
    "\t\t\t('f_89', f_89),\n",
    "\t\t\t('f_90', f_90),\n",
    "\t\t\t('f_91', f_91),\n",
    "\t\t\t('f_92', f_92),\n",
    "\t\t\t('f_93', f_93),\n",
    "\t\t\t('f_94', f_94),\n",
    "\t\t\t('f_95', f_95),\n",
    "\t\t\t('f_96', f_96),\n",
    "\t\t\t('f_97', f_97),\n",
    "\t\t\t('f_98', f_98),\n",
    "\t\t\t('f_99', f_99),\n",
    "\t\t\t('f_100', f_100),\n",
    "\t\t\t('f_101', f_101),\n",
    "\t\t\t('f_102', f_102),\n",
    "\t\t\t('f_103', f_103),\n",
    "\t\t\t('f_104', f_104),\n",
    "\t\t\t('f_105', f_105),\n",
    "\t\t\t('f_106', f_106),\n",
    "\t\t\t('f_107', f_107),\n",
    "\t\t\t('f_108', f_108),\n",
    "\t\t\t('f_109', f_109),\n",
    "\t\t\t('f_110', f_110),\n",
    "\t\t\t('f_111', f_111),\n",
    "\t\t\t('f_112', f_112),\n",
    "\t\t\t('f_113', f_113),\n",
    "\t\t\t('f_114', f_114),\n",
    "\t\t\t('f_115', f_115),\n",
    "\t\t\t('f_116', f_116),\n",
    "\t\t\t('f_117', f_117),\n",
    "\t\t\t('f_118', f_118),\n",
    "\t\t\t('f_119', f_119),\n",
    "\t\t\t('f_120', f_120),\n",
    "\t\t\t('f_121', f_121),\n",
    "\t\t\t('f_122', f_122),\n",
    "\t\t\t('f_123', f_123),\n",
    "\t\t\t('f_124', f_124),\n",
    "\t\t\t('f_125', f_125),\n",
    "\t\t\t('f_126', f_126),\n",
    "\t\t\t('f_127', f_127),\n",
    "\t\t\t('f_128', f_128),\n",
    "\t\t\t('f_129', f_129),\n",
    "\t\t\t('f_130', f_130),\n",
    "\t\t\t('f_131', f_131),\n",
    "\t\t\t('f_132', f_132),\n",
    "\t\t\t('f_133', f_133),\n",
    "\t\t\t('f_134', f_134),\n",
    "\t\t\t('f_135', f_135),\n",
    "\t\t\t('f_136', f_136),\n",
    "\t\t\t('f_137', f_137),\n",
    "\t\t\t('f_138', f_138),\n",
    "\t\t\t('f_139', f_139),\n",
    "\t\t\t('f_140', f_140),\n",
    "\t\t\t('f_141', f_141),\n",
    "\t\t\t('f_142', f_142),\n",
    "\t\t\t('f_143', f_143),\n",
    "\t\t\t('f_144', f_144),\n",
    "\t\t\t('f_145', f_145),\n",
    "\t\t\t('f_146', f_146),\n",
    "\t\t\t('f_147', f_147),\n",
    "\t\t\t('f_148', f_148),\n",
    "\t\t\t('f_149', f_149),\n",
    "\t\t\t('f_150', f_150),\n",
    "\t\t\t('f_151', f_151),\n",
    "\t\t\t('f_152', f_152),\n",
    "\t\t\t('f_153', f_153),\n",
    "\t\t\t('f_154', f_154),\n",
    "\t\t\t('f_155', f_155),\n",
    "\t\t\t('f_156', f_156),\n",
    "\t\t\t('f_157', f_157),\n",
    "\t\t\t('f_158', f_158),\n",
    "\t\t\t('f_159', f_159),\n",
    "\t\t\t('f_160', f_160),\n",
    "\t\t\t('f_161', f_161),\n",
    "\t\t\t('f_162', f_162),\n",
    "\t\t\t('f_163', f_163),\n",
    "\t\t\t('f_164', f_164),\n",
    "\t\t\t('f_165', f_165),\n",
    "\t\t\t('f_166', f_166),\n",
    "\t\t\t('f_167', f_167),\n",
    "\t\t\t('f_168', f_168),\n",
    "\t\t\t('f_169', f_169),\n",
    "\t\t\t('f_170', f_170),\n",
    "\t\t\t('f_171', f_171),\n",
    "\t\t\t('f_172', f_172),\n",
    "\t\t\t('f_173', f_173),\n",
    "\t\t\t('f_174', f_174),\n",
    "\t\t\t('f_175', f_175),\n",
    "\t\t\t('f_176', f_176),\n",
    "\t\t\t('f_177', f_177),\n",
    "\t\t\t('f_178', f_178),\n",
    "\t\t\t('f_179', f_179),\n",
    "\t\t\t('f_180', f_180),\n",
    "\t\t\t('f_181', f_181),\n",
    "\t\t\t('f_182', f_182),\n",
    "\t\t\t('f_183', f_183),\n",
    "\t\t\t('f_184', f_184),\n",
    "\t\t\t('f_185', f_185),\n",
    "\t\t\t('f_186', f_186),\n",
    "\t\t\t('f_187', f_187),\n",
    "\t\t\t('f_188', f_188),\n",
    "\t\t\t('f_189', f_189),\n",
    "\t\t\t('f_190', f_190),\n",
    "\t\t\t('f_191', f_191),\n",
    "\t\t\t('f_192', f_192),\n",
    "\t\t\t('f_193', f_193),\n",
    "\t\t\t('f_194', f_194),\n",
    "\t\t\t('f_195', f_195),\n",
    "\t\t\t('f_196', f_196),\n",
    "\t\t\t('f_197', f_197),\n",
    "\t\t\t('f_198', f_198),\n",
    "\t\t\t('f_199', f_199),\n",
    "\t\t\t('f_200', f_200),\n",
    "\t\t\t('f_201', f_201),\n",
    "\t\t\t('f_202', f_202),\n",
    "\t\t\t('f_203', f_203),\n",
    "\t\t\t('f_204', f_204),\n",
    "\t\t\t('f_205', f_205),\n",
    "\t\t\t('f_206', f_206),\n",
    "\t\t\t('f_207', f_207),\n",
    "\t\t\t('f_208', f_208),\n",
    "\t\t\t('f_209', f_209),\n",
    "\t\t\t('f_210', f_210),\n",
    "\t\t\t('f_211', f_211),\n",
    "\t\t\t('f_212', f_212),\n",
    "\t\t\t('f_213', f_213),\n",
    "\t\t\t('f_214', f_214),\n",
    "\t\t\t('f_215', f_215),\n",
    "\t\t\t('f_216', f_216),\n",
    "\t\t\t('f_217', f_217),\n",
    "\t\t\t('f_218', f_218),\n",
    "\t\t\t('f_219', f_219),\n",
    "\t\t\t('f_220', f_220),\n",
    "\t\t\t('f_221', f_221),\n",
    "\t\t\t('f_222', f_222),\n",
    "\t\t\t('f_223', f_223),\n",
    "\t\t\t('f_224', f_224),\n",
    "\t\t\t('f_225', f_225),\n",
    "\t\t\t('f_226', f_226),\n",
    "\t\t\t('f_227', f_227),\n",
    "\t\t\t('f_228', f_228),\n",
    "\t\t\t('f_229', f_229),\n",
    "\t\t\t('f_230', f_230),\n",
    "\t\t\t('f_231', f_231),\n",
    "\t\t\t('f_232', f_232),\n",
    "\t\t\t('f_233', f_233),\n",
    "\t\t\t('f_234', f_234),\n",
    "\t\t\t('f_235', f_235),\n",
    "\t\t\t('f_236', f_236),\n",
    "\t\t\t('f_237', f_237),\n",
    "\t\t\t('f_238', f_238),\n",
    "\t\t\t('f_239', f_239),\n",
    "\t\t\t('f_240', f_240),\n",
    "\t\t\t('f_241', f_241),\n",
    "\t\t\t('f_242', f_242),\n",
    "\t\t\t('f_243', f_243),\n",
    "\t\t\t('f_244', f_244),\n",
    "\t\t\t('f_245', f_245),\n",
    "\t\t\t('f_246', f_246),\n",
    "\t\t\t('f_247', f_247),\n",
    "\t\t\t('f_248', f_248),\n",
    "\t\t\t('f_249', f_249),\n",
    "\t\t\t('f_250', f_250) ]\n",
    "\t\t) as features,\n",
    "\t\t1 as key\n",
    "\tfrom semantics_score_district_temp\n",
    "),\n",
    "\n",
    "district_similarity as (\n",
    "select a.district_id as from_district_id,\n",
    "\tb.district_id as to_district_id,\n",
    "\tcast(\n",
    "\t\tround(cosine_similarity(a.features, b.features), 2) * 100 as int\n",
    "\t) as similarity\n",
    "from semantics_score_district_map a\n",
    "\tleft join semantics_score_district_map b on a.key = b.key\n",
    "group by 1, 2, 3\n",
    "),\n",
    "\n",
    "output as (\n",
    "select * from awsdatacatalog.feature_store.avl_training_output_v2\n",
    "where sp_id in (select sp_id from single_truck_sps)\n",
    "and district_id in (select district_id from district_boundaries)\n",
    "),\n",
    "\n",
    "gps_merge_temp as (\n",
    "select o.*,\n",
    "s.truck_number,\n",
    "gps.entity as district_id_gps,\n",
    "gps.event_timestamp as event_timestamp_gps,\n",
    "gps.total_dwell_time,\n",
    "gps.total_speed,\n",
    "gps.total_is_ignition_off,\n",
    "gps.total_records,\n",
    "d.distance,\n",
    "ROW_NUMBER() OVER (PARTITION BY o.sp_id, o.event_timestamp, o.district_id ORDER BY gps.event_timestamp DESC) as rnk,\n",
    "\n",
    "case\n",
    "    when gps.entity = LAG(gps.entity, 1) OVER (PARTITION BY o.sp_id, o.event_timestamp, o.district_id ORDER BY gps.event_timestamp DESC) then 0\n",
    "    else 1\n",
    "end as flag,\n",
    "date_diff('day',gps.event_timestamp,o.event_timestamp) as time_diff,\n",
    "case\n",
    "    when date_diff('day',gps.event_timestamp,o.event_timestamp)<=1 then 'day_1'\n",
    "     when date_diff('day',gps.event_timestamp,o.event_timestamp)<=2 and date_diff('day',gps.event_timestamp,o.event_timestamp)>1 then 'day_2'\n",
    "     when date_diff('day',gps.event_timestamp,o.event_timestamp)<=3 and date_diff('day',gps.event_timestamp,o.event_timestamp)>2 then 'day_3' \n",
    "     when date_diff('day',gps.event_timestamp,o.event_timestamp)<=4 and date_diff('day',gps.event_timestamp,o.event_timestamp)>3 then 'day_4' \n",
    "     when date_diff('day',gps.event_timestamp,o.event_timestamp)<=5 and date_diff('day',gps.event_timestamp,o.event_timestamp)>4 then 'day_5' \n",
    "    else 'others'\n",
    "end as day_flag\n",
    "\n",
    "from output o\n",
    "inner join single_truck_sps s on s.sp_id = o.sp_id\n",
    "inner join gps_features_district gps on s.truck_number = gps.truck_number and o.event_timestamp>gps.event_timestamp and gps.event_timestamp>=o.event_timestamp - interval '5' day\n",
    "inner join distict_distance d on d.from_district_id = o.district_id and d.to_district_id = gps.entity\n",
    "),\n",
    "\n",
    "gps_day_level_temp as (\n",
    "select \n",
    "id,\n",
    "sp_id,\n",
    "truck_number,\n",
    "district_id,\n",
    "event_timestamp,\n",
    "day_flag,\n",
    "availability_flag,\n",
    "max(total_dwell_time) as total_dwell_time,\n",
    "max(total_is_ignition_off) as total_is_ignition_off,\n",
    "max_by(district_id_gps,total_dwell_time) as district_id_gps\n",
    "from gps_merge_temp\n",
    "group by 1,2,3,4,5,6,7\n",
    "),\n",
    "\n",
    "day_level_feat as (\n",
    "select gps.*, \n",
    "d.similarity as district_similarity\n",
    "\n",
    "from gps_day_level_temp gps \n",
    "inner join district_similarity d on gps.district_id = d.from_district_id and gps.district_id_gps = d.to_district_id\n",
    "\n",
    "),\n",
    "final_data as (\n",
    "select \n",
    "id, sp_id,truck_number, event_timestamp, district_id,\n",
    "case when availability_flag = 'AVAILABLE' then 1 else 0 end as available_flag,\n",
    "-- sum(dwell_time) as total_dwell_time\n",
    "array_agg(array[cast(district_similarity as int), cast(total_dwell_time as int), cast(total_is_ignition_off as int)] order by event_timestamp ASC) as st_features\n",
    "from day_level_feat\n",
    "group by 1,2,3,4,5,6\n",
    "order by sp_id, event_timestamp, district_id\n",
    "\n",
    "),\n",
    "\n",
    "final_merge_temp as (\n",
    "select \n",
    "f.id, \n",
    "f.sp_id,\n",
    "f.truck_number, \n",
    "f.event_timestamp, \n",
    "f.available_flag,\n",
    "f.district_id,\n",
    "f.st_features,\n",
    "max_by(gps_agg.total_dwell_time,gps_agg.event_timestamp) as total_dwell_time,\n",
    "max_by(gps_agg.total_speed,gps_agg.event_timestamp) as total_speed_agg,\n",
    "max_by(gps_agg.total_is_ignition_off,gps_agg.event_timestamp) as total_is_ignition_off_agg,\n",
    "max_by(gps_agg.total_records,gps_agg.event_timestamp) as total_records_agg\n",
    "from final_data f\n",
    "inner join gps_features_district_aggregate gps_agg on f.truck_number = gps_agg.truck_number and f.district_id = gps_agg.entity and f.event_timestamp>gps_agg.event_timestamp\n",
    "group by 1,2,3,4,5,6,7)\n",
    "\n",
    "select \n",
    "id, \n",
    "sp_id,\n",
    "truck_number, \n",
    "event_timestamp, \n",
    "available_flag,\n",
    "district_id,\n",
    "st_features,\n",
    "ARRAY[cast(COALESCE(total_dwell_time,0) as int), \n",
    "         cast(COALESCE(total_speed_agg,0) as int),\n",
    "         cast(COALESCE(total_is_ignition_off_agg,0) as int),\n",
    "         cast(COALESCE(total_records_agg,0) as int)] as agg_features\n",
    "from final_merge_temp\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "101b2236",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "    with sp_mapping_temp as (\n",
    "    SELECT  id as fleet_owner_id, max_by(cast(phone_no as varchar), updated_at) as mobile_no,\n",
    "    max_by(cast(iam_id as int), updated_at) as sp_id  FROM  \"awsdatacatalog\".\"supply_team\".\"supply_team_blackbuck_fleetapp_fleetowner\"\n",
    "    group by 1\n",
    "    ),\n",
    "\n",
    "    sp_mapping as (\n",
    "    select fleet_owner_id, mobile_no, cast(sp_id as bigint) as sp_id \n",
    "    from sp_mapping_temp \n",
    "    where mobile_no in (\n",
    "    select mobile_no from (\n",
    "    select mobile_no, count(*) as sp_count from sp_mapping_temp\n",
    "    group by 1\n",
    "    having count(*)<=1))\n",
    "    ),\n",
    "\n",
    "    --- Truck Mapping to SP ID\n",
    "    truck_mapping as (\n",
    "    select ft.id as truck_id,\n",
    "    ft.truck_no as truck_number,\n",
    "    tor.fleet_owner_id as fleet_owner_id,\n",
    "    s.sp_id\n",
    "    from \"awsdatacatalog\".\"supply_team\".\"supply_team_blackbuck_fleetapp_truck\" ft\n",
    "    inner join \"awsdatacatalog\".\"supply_team\".\"supply_team_blackbuck_truck_owner_request\" tor on ft.id = tor.truck_id\n",
    "    inner join sp_mapping s on s.fleet_owner_id = tor.fleet_owner_id\n",
    "    where \n",
    "    ft.truck_no != ''\n",
    "    and tor.fleet_owner_id is not null\n",
    "    and tor.kyc_status_v2 ='APPROVED'\n",
    "    and ft.is_truck = 'VERIFIED'\n",
    "    and ft.is_verified != 3\n",
    "    group by 1,2,3,4\n",
    "    ),\n",
    "\n",
    "    --- Single Truck FOs/SPs\n",
    "    single_truck_sps as (\n",
    "    select\n",
    "    tm.*,\n",
    "    tmc.number_of_trucks\n",
    "    from truck_mapping tm\n",
    "    left join (select sp_id, count(distinct truck_number) as number_of_trucks from truck_mapping group by 1) tmc on tmc.sp_id = tm.sp_id\n",
    "    where tmc.number_of_trucks = 1\n",
    "    ),\n",
    "\n",
    "    ------ Plaza to District Mapping\n",
    "    district_boundaries as (\n",
    "    select place_id as district_id, \n",
    "    name as district_name, \n",
    "    ST_GeomFromBinary(from_hex(to_utf8(replace(boundary_geog,'20E61000')))) as boundary_geog,\n",
    "    ST_X(ST_Centroid(ST_GeomFromBinary(from_hex(to_utf8(replace(boundary_geog,'20E61000')))))) as longitude,\n",
    "    ST_Y(ST_Centroid(ST_GeomFromBinary(from_hex(to_utf8(replace(boundary_geog,'20E61000')))))) as latitude\n",
    "    from location_service.public.admin_area where deleted = false\n",
    "    and local_tag = 'DISTRICT'\n",
    "    and boundary_geog != ''\n",
    "    ),\n",
    "\n",
    "    distict_distance as (\n",
    "    select a.district_id as from_district_id,\n",
    "    b.district_id as to_district_id,\n",
    "    cast(great_circle_distance(a.latitude, a.longitude, b.latitude, b.longitude) as int) as distance\n",
    "    from district_boundaries a\n",
    "    cross join district_boundaries b\n",
    "    ),\n",
    "\n",
    "    ---- Semantics District Vectors\n",
    "    semantics_score_district_temp as (\n",
    "        SELECT *\n",
    "        FROM (\n",
    "                SELECT t.*,\n",
    "                    ROW_NUMBER() OVER (\n",
    "                        PARTITION BY bb_place_id\n",
    "                        ORDER BY created_timestamp DESC\n",
    "                    ) AS rnk\n",
    "                FROM \"awsdatacatalog\".\"feature_store\".\"semantics_from_district\" t\n",
    "            )\n",
    "        WHERE rnk = 1\n",
    "    ),\n",
    "\n",
    "    semantics_score_district_map as (\n",
    "        select bb_place_id as district_id,\n",
    "            MAP_FROM_ENTRIES(\n",
    "                ARRAY [ ('f_1', f_1),\n",
    "                ('f_2', f_2),\n",
    "                ('f_3', f_3),\n",
    "                ('f_4', f_4),\n",
    "                ('f_5', f_5),\n",
    "                ('f_6', f_6),\n",
    "                ('f_7', f_7),\n",
    "                ('f_8', f_8),\n",
    "                ('f_9', f_9),\n",
    "                ('f_10', f_10),\n",
    "                ('f_11', f_11),\n",
    "                ('f_12', f_12),\n",
    "                ('f_13', f_13),\n",
    "                ('f_14', f_14),\n",
    "                ('f_15', f_15),\n",
    "                ('f_16', f_16),\n",
    "                ('f_17', f_17),\n",
    "                ('f_18', f_18),\n",
    "                ('f_19', f_19),\n",
    "                ('f_20', f_20),\n",
    "                ('f_21', f_21),\n",
    "                ('f_22', f_22),\n",
    "                ('f_23', f_23),\n",
    "                ('f_24', f_24),\n",
    "                ('f_25', f_25),\n",
    "                ('f_26', f_26),\n",
    "                ('f_27', f_27),\n",
    "                ('f_28', f_28),\n",
    "                ('f_29', f_29),\n",
    "                ('f_30', f_30),\n",
    "                ('f_31', f_31),\n",
    "                ('f_32', f_32),\n",
    "                ('f_33', f_33),\n",
    "                ('f_34', f_34),\n",
    "                ('f_35', f_35),\n",
    "                ('f_36', f_36),\n",
    "                ('f_37', f_37),\n",
    "                ('f_38', f_38),\n",
    "                ('f_39', f_39),\n",
    "                ('f_40', f_40),\n",
    "                ('f_41', f_41),\n",
    "                ('f_42', f_42),\n",
    "                ('f_43', f_43),\n",
    "                ('f_44', f_44),\n",
    "                ('f_45', f_45),\n",
    "                ('f_46', f_46),\n",
    "                ('f_47', f_47),\n",
    "                ('f_48', f_48),\n",
    "                ('f_49', f_49),\n",
    "                ('f_50', f_50),\n",
    "                ('f_51', f_51),\n",
    "                ('f_52', f_52),\n",
    "                ('f_53', f_53),\n",
    "                ('f_54', f_54),\n",
    "                ('f_55', f_55),\n",
    "                ('f_56', f_56),\n",
    "                ('f_57', f_57),\n",
    "                ('f_58', f_58),\n",
    "                ('f_59', f_59),\n",
    "                ('f_60', f_60),\n",
    "                ('f_61', f_61),\n",
    "                ('f_62', f_62),\n",
    "                ('f_63', f_63),\n",
    "                ('f_64', f_64),\n",
    "                ('f_65', f_65),\n",
    "                ('f_66', f_66),\n",
    "                ('f_67', f_67),\n",
    "                ('f_68', f_68),\n",
    "                ('f_69', f_69),\n",
    "                ('f_70', f_70),\n",
    "                ('f_71', f_71),\n",
    "                ('f_72', f_72),\n",
    "                ('f_73', f_73),\n",
    "                ('f_74', f_74),\n",
    "                ('f_75', f_75),\n",
    "                ('f_76', f_76),\n",
    "                ('f_77', f_77),\n",
    "                ('f_78', f_78),\n",
    "                ('f_79', f_79),\n",
    "                ('f_80', f_80),\n",
    "                ('f_81', f_81),\n",
    "                ('f_82', f_82),\n",
    "                ('f_83', f_83),\n",
    "                ('f_84', f_84),\n",
    "                ('f_85', f_85),\n",
    "                ('f_86', f_86),\n",
    "                ('f_87', f_87),\n",
    "                ('f_88', f_88),\n",
    "                ('f_89', f_89),\n",
    "                ('f_90', f_90),\n",
    "                ('f_91', f_91),\n",
    "                ('f_92', f_92),\n",
    "                ('f_93', f_93),\n",
    "                ('f_94', f_94),\n",
    "                ('f_95', f_95),\n",
    "                ('f_96', f_96),\n",
    "                ('f_97', f_97),\n",
    "                ('f_98', f_98),\n",
    "                ('f_99', f_99),\n",
    "                ('f_100', f_100),\n",
    "                ('f_101', f_101),\n",
    "                ('f_102', f_102),\n",
    "                ('f_103', f_103),\n",
    "                ('f_104', f_104),\n",
    "                ('f_105', f_105),\n",
    "                ('f_106', f_106),\n",
    "                ('f_107', f_107),\n",
    "                ('f_108', f_108),\n",
    "                ('f_109', f_109),\n",
    "                ('f_110', f_110),\n",
    "                ('f_111', f_111),\n",
    "                ('f_112', f_112),\n",
    "                ('f_113', f_113),\n",
    "                ('f_114', f_114),\n",
    "                ('f_115', f_115),\n",
    "                ('f_116', f_116),\n",
    "                ('f_117', f_117),\n",
    "                ('f_118', f_118),\n",
    "                ('f_119', f_119),\n",
    "                ('f_120', f_120),\n",
    "                ('f_121', f_121),\n",
    "                ('f_122', f_122),\n",
    "                ('f_123', f_123),\n",
    "                ('f_124', f_124),\n",
    "                ('f_125', f_125),\n",
    "                ('f_126', f_126),\n",
    "                ('f_127', f_127),\n",
    "                ('f_128', f_128),\n",
    "                ('f_129', f_129),\n",
    "                ('f_130', f_130),\n",
    "                ('f_131', f_131),\n",
    "                ('f_132', f_132),\n",
    "                ('f_133', f_133),\n",
    "                ('f_134', f_134),\n",
    "                ('f_135', f_135),\n",
    "                ('f_136', f_136),\n",
    "                ('f_137', f_137),\n",
    "                ('f_138', f_138),\n",
    "                ('f_139', f_139),\n",
    "                ('f_140', f_140),\n",
    "                ('f_141', f_141),\n",
    "                ('f_142', f_142),\n",
    "                ('f_143', f_143),\n",
    "                ('f_144', f_144),\n",
    "                ('f_145', f_145),\n",
    "                ('f_146', f_146),\n",
    "                ('f_147', f_147),\n",
    "                ('f_148', f_148),\n",
    "                ('f_149', f_149),\n",
    "                ('f_150', f_150),\n",
    "                ('f_151', f_151),\n",
    "                ('f_152', f_152),\n",
    "                ('f_153', f_153),\n",
    "                ('f_154', f_154),\n",
    "                ('f_155', f_155),\n",
    "                ('f_156', f_156),\n",
    "                ('f_157', f_157),\n",
    "                ('f_158', f_158),\n",
    "                ('f_159', f_159),\n",
    "                ('f_160', f_160),\n",
    "                ('f_161', f_161),\n",
    "                ('f_162', f_162),\n",
    "                ('f_163', f_163),\n",
    "                ('f_164', f_164),\n",
    "                ('f_165', f_165),\n",
    "                ('f_166', f_166),\n",
    "                ('f_167', f_167),\n",
    "                ('f_168', f_168),\n",
    "                ('f_169', f_169),\n",
    "                ('f_170', f_170),\n",
    "                ('f_171', f_171),\n",
    "                ('f_172', f_172),\n",
    "                ('f_173', f_173),\n",
    "                ('f_174', f_174),\n",
    "                ('f_175', f_175),\n",
    "                ('f_176', f_176),\n",
    "                ('f_177', f_177),\n",
    "                ('f_178', f_178),\n",
    "                ('f_179', f_179),\n",
    "                ('f_180', f_180),\n",
    "                ('f_181', f_181),\n",
    "                ('f_182', f_182),\n",
    "                ('f_183', f_183),\n",
    "                ('f_184', f_184),\n",
    "                ('f_185', f_185),\n",
    "                ('f_186', f_186),\n",
    "                ('f_187', f_187),\n",
    "                ('f_188', f_188),\n",
    "                ('f_189', f_189),\n",
    "                ('f_190', f_190),\n",
    "                ('f_191', f_191),\n",
    "                ('f_192', f_192),\n",
    "                ('f_193', f_193),\n",
    "                ('f_194', f_194),\n",
    "                ('f_195', f_195),\n",
    "                ('f_196', f_196),\n",
    "                ('f_197', f_197),\n",
    "                ('f_198', f_198),\n",
    "                ('f_199', f_199),\n",
    "                ('f_200', f_200),\n",
    "                ('f_201', f_201),\n",
    "                ('f_202', f_202),\n",
    "                ('f_203', f_203),\n",
    "                ('f_204', f_204),\n",
    "                ('f_205', f_205),\n",
    "                ('f_206', f_206),\n",
    "                ('f_207', f_207),\n",
    "                ('f_208', f_208),\n",
    "                ('f_209', f_209),\n",
    "                ('f_210', f_210),\n",
    "                ('f_211', f_211),\n",
    "                ('f_212', f_212),\n",
    "                ('f_213', f_213),\n",
    "                ('f_214', f_214),\n",
    "                ('f_215', f_215),\n",
    "                ('f_216', f_216),\n",
    "                ('f_217', f_217),\n",
    "                ('f_218', f_218),\n",
    "                ('f_219', f_219),\n",
    "                ('f_220', f_220),\n",
    "                ('f_221', f_221),\n",
    "                ('f_222', f_222),\n",
    "                ('f_223', f_223),\n",
    "                ('f_224', f_224),\n",
    "                ('f_225', f_225),\n",
    "                ('f_226', f_226),\n",
    "                ('f_227', f_227),\n",
    "                ('f_228', f_228),\n",
    "                ('f_229', f_229),\n",
    "                ('f_230', f_230),\n",
    "                ('f_231', f_231),\n",
    "                ('f_232', f_232),\n",
    "                ('f_233', f_233),\n",
    "                ('f_234', f_234),\n",
    "                ('f_235', f_235),\n",
    "                ('f_236', f_236),\n",
    "                ('f_237', f_237),\n",
    "                ('f_238', f_238),\n",
    "                ('f_239', f_239),\n",
    "                ('f_240', f_240),\n",
    "                ('f_241', f_241),\n",
    "                ('f_242', f_242),\n",
    "                ('f_243', f_243),\n",
    "                ('f_244', f_244),\n",
    "                ('f_245', f_245),\n",
    "                ('f_246', f_246),\n",
    "                ('f_247', f_247),\n",
    "                ('f_248', f_248),\n",
    "                ('f_249', f_249),\n",
    "                ('f_250', f_250) ]\n",
    "            ) as features,\n",
    "            1 as key\n",
    "        from semantics_score_district_temp\n",
    "    ),\n",
    "\n",
    "    district_similarity as (\n",
    "    select a.district_id as from_district_id,\n",
    "        b.district_id as to_district_id,\n",
    "        cast(\n",
    "            round(cosine_similarity(a.features, b.features), 2) * 100 as int\n",
    "        ) as similarity\n",
    "    from semantics_score_district_map a\n",
    "        left join semantics_score_district_map b on a.key = b.key\n",
    "    group by 1, 2, 3\n",
    "    ),\n",
    "\n",
    "    output as (\n",
    "    select * from awsdatacatalog.feature_store.avl_training_output_v2\n",
    "    where sp_id in (select sp_id from single_truck_sps)\n",
    "    and district_id in (select district_id from district_boundaries)\n",
    "    ),\n",
    "    --- Merge Output with GPS Transactions data\n",
    "    gps_merge_temp as (\n",
    "    select o.*,\n",
    "    s.truck_number,\n",
    "    gps.entity as district_id_gps,\n",
    "    gps.event_timestamp as event_timestamp_gps,\n",
    "    gps.total_dwell_time,\n",
    "    gps.total_speed,\n",
    "    gps.total_is_ignition_off,\n",
    "    gps.total_records,\n",
    "    d.distance,\n",
    "\n",
    "    case\n",
    "        when gps.entity = LAG(gps.entity, 1) OVER (PARTITION BY o.id ORDER BY gps.event_timestamp DESC) then 0\n",
    "\n",
    "        else 1\n",
    "    end as flag,\n",
    "    date_diff('day',gps.event_timestamp,o.event_timestamp) as time_diff,\n",
    "    case\n",
    "        when date_diff('day',gps.event_timestamp,o.event_timestamp)<=1 then 'day_1'\n",
    "         when date_diff('day',gps.event_timestamp,o.event_timestamp)<=2 and date_diff('day',gps.event_timestamp,o.event_timestamp)>1 then 'day_2'\n",
    "         when date_diff('day',gps.event_timestamp,o.event_timestamp)<=3 and date_diff('day',gps.event_timestamp,o.event_timestamp)>2 then 'day_3'\n",
    "         when date_diff('day',gps.event_timestamp,o.event_timestamp)<=4 and date_diff('day',gps.event_timestamp,o.event_timestamp)>3 then 'day_4'\n",
    "         when date_diff('day',gps.event_timestamp,o.event_timestamp)<=5 and date_diff('day',gps.event_timestamp,o.event_timestamp)>4 then 'day_5'\n",
    "        else 'others'\n",
    "    end as day_flag\n",
    "\n",
    "    from output o\n",
    "    inner join single_truck_sps s on s.sp_id = o.sp_id\n",
    "    inner join gps_features_district gps on s.truck_number = gps.truck_number and o.event_timestamp>gps.event_timestamp and gps.event_timestamp>=o.event_timestamp - interval '5' day\n",
    "    inner join distict_distance d on d.from_district_id = o.district_id and d.to_district_id = gps.entity\n",
    "    ),\n",
    "\n",
    "    gps_day_level_temp as (\n",
    "    select\n",
    "    id,\n",
    "    sp_id,\n",
    "    truck_number,\n",
    "    district_id,\n",
    "    state_id,\n",
    "    event_timestamp,\n",
    "    day_flag,\n",
    "    availability_flag,\n",
    "    max(total_dwell_time) as total_dwell_time,\n",
    "    max_by(total_is_ignition_off, total_dwell_time) as total_is_ignition_off,\n",
    "    max_by(district_id_gps, total_dwell_time) as district_id_gps\n",
    "    from gps_merge_temp\n",
    "    where day_flag != 'others'\n",
    "    group by 1,2,3,4,5,6,7,8\n",
    "    ),\n",
    "\n",
    "    day_level_features as (\n",
    "    select gps.*,\n",
    "    COALESCE(d.similarity, -100) as district_similarity\n",
    "    from gps_day_level_temp gps\n",
    "    left join district_similarity d on gps.district_id = d.from_district_id and gps.district_id_gps = d.to_district_id\n",
    "    ),\n",
    "\n",
    "\n",
    "    gps_trajectory as (\n",
    "    select\n",
    "    id,\n",
    "    sp_id,\n",
    "    truck_number,\n",
    "    event_timestamp,\n",
    "    district_id, state_id,\n",
    "    availability_flag,\n",
    "    array_agg(array[cast(district_similarity as int), cast(total_dwell_time as int), cast(total_is_ignition_off as int)] order by day_flag ASC) as st_features\n",
    "    from day_level_features\n",
    "    group by 1,2,3,4,5,6,7\n",
    "    order by sp_id, event_timestamp, district_id\n",
    "    ),\n",
    "\n",
    "    gps_district_characteristics_temp as (\n",
    "    select\n",
    "    f.id,\n",
    "    f.truck_number,\n",
    "    max_by(gps_agg.total_dwell_time, gps_agg.event_timestamp) as total_dwell_time,\n",
    "    max_by(gps_agg.total_speed, gps_agg.event_timestamp) as total_speed_agg,\n",
    "    max_by(gps_agg.total_is_ignition_off, gps_agg.event_timestamp) as total_is_ignition_off_agg,\n",
    "    max_by(gps_agg.total_records, gps_agg.event_timestamp) as total_records_agg\n",
    "    from gps_merge_temp f\n",
    "    inner join gps_features_district_aggregate gps_agg on f.truck_number = gps_agg.truck_number and f.district_id = gps_agg.entity\n",
    "    and f.event_timestamp>gps_agg.event_timestamp\n",
    "    group by 1,2\n",
    "    ),\n",
    "\n",
    "    gps_district_characteristics as (\n",
    "    select\n",
    "    id,\n",
    "    ARRAY[cast(COALESCE(total_dwell_time,0) as int),\n",
    "             cast(COALESCE(total_speed_agg,0) as int),\n",
    "             cast(COALESCE(total_is_ignition_off_agg,0) as int),\n",
    "             cast(COALESCE(total_records_agg,0) as int)] as agg_features\n",
    "    from gps_district_characteristics_temp\n",
    "    )\n",
    "    select\n",
    "    o.id,o.sp_id,s.truck_number,o.event_timestamp,case when o.availability_flag = 'AVAILABLE' then 1 else 0 end as available_flag,  o.district_id,\n",
    "    gps_tj.st_features,\n",
    "    gps_agg.agg_features\n",
    "    from output o\n",
    "    inner join single_truck_sps s on s.sp_id = o.sp_id\n",
    "    inner join gps_trajectory gps_tj on gps_tj.id=o.id\n",
    "    inner join gps_district_characteristics gps_agg on gps_agg.id = o.id\n",
    "    group by 1,2,3,4,5,6,7,8\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44067a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= wr.athena.read_sql_query(query_new, \n",
    "                                   database = config.feature_db, \n",
    "                                   workgroup = config.work_group,\n",
    "                                   s3_output = config.s3_athena_output,\n",
    "                               ctas_approach=True\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8099dd89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80537, 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2eff4f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80537"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33ed0333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'sp_id', 'truck_number', 'event_timestamp', 'available_flag',\n",
       "       'district_id', 'st_features', 'agg_features'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da4aebc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5168"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['truck_number'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "051e7153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "568"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['district_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46b6794c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "\n",
    "with output as (\n",
    "select * from avl_training_output_v2\n",
    "),\n",
    "\n",
    "------- District Long Term Features\n",
    "sp_district_features_temp as (\n",
    "select * from avl_sp_district_lt\n",
    "),\n",
    "\n",
    "sp_district_features as (\n",
    "SELECT sp_id, event_timestamp, district_id,\n",
    "find_loads,\n",
    "indent_click,\n",
    "select_truck_type,\n",
    "book_load,\n",
    "bid,\n",
    "call,\n",
    "confirm_booking,\n",
    "search\n",
    "FROM\n",
    "(\n",
    "SELECT t.sp_id, t.event_timestamp, t.district_id,\n",
    "t.find_loads,\n",
    "t.indent_click,\n",
    "t.select_truck_type,\n",
    "t.book_load,\n",
    "t.bid,\n",
    "t.call,\n",
    "t.confirm_booking,\n",
    "t.search,\n",
    "ROW_NUMBER() OVER (PARTITION BY sp_id, district_id, event_timestamp\n",
    "              ORDER BY created_timestamp DESC) AS rnk\n",
    "FROM sp_district_features_temp t\n",
    ")\n",
    "WHERE rnk = 1\n",
    "),\n",
    "\n",
    "\n",
    "------- District Long Term Features (Max)\n",
    "sp_district_features_max_temp as (\n",
    "select * from avl_sp_district_lt_max\n",
    "),\n",
    "\n",
    "sp_district_features_max as (\n",
    "SELECT sp_id, event_timestamp,\n",
    "find_loads,\n",
    "indent_click,\n",
    "select_truck_type,\n",
    "book_load,\n",
    "bid,\n",
    "call,\n",
    "confirm_booking,\n",
    "search\n",
    "FROM\n",
    "(\n",
    "SELECT t.sp_id, t.event_timestamp,\n",
    "t.find_loads,\n",
    "t.indent_click,\n",
    "t.select_truck_type,\n",
    "t.book_load,\n",
    "t.bid,\n",
    "t.call,\n",
    "t.confirm_booking,\n",
    "t.search,\n",
    "ROW_NUMBER() OVER (PARTITION BY sp_id, event_timestamp\n",
    "              ORDER BY created_timestamp DESC) AS rnk\n",
    "FROM sp_district_features_max_temp t\n",
    ")\n",
    "WHERE rnk = 1\n",
    "),\n",
    "\n",
    "\n",
    "\n",
    "-----State Long Term Features\n",
    "sp_state_features_temp as (\n",
    "select * from avl_sp_state_lt\n",
    "),\n",
    "\n",
    "sp_state_features as (\n",
    "SELECT sp_id, event_timestamp, state_id,\n",
    "find_loads,\n",
    "indent_click,\n",
    "select_truck_type,\n",
    "book_load,\n",
    "bid,\n",
    "call,\n",
    "confirm_booking,\n",
    "search\n",
    "FROM\n",
    "(\n",
    "SELECT t.sp_id, t.event_timestamp, t.state_id,\n",
    "t.find_loads,\n",
    "t.indent_click,\n",
    "t.select_truck_type,\n",
    "t.book_load,\n",
    "t.bid,\n",
    "t.call,\n",
    "t.confirm_booking,\n",
    "t.search,\n",
    "ROW_NUMBER() OVER (PARTITION BY sp_id, state_id, event_timestamp\n",
    "              ORDER BY created_timestamp DESC) AS rnk\n",
    "FROM sp_state_features_temp t\n",
    ") \n",
    "WHERE rnk = 1\n",
    "),\n",
    "\n",
    "\n",
    "\n",
    "-----State Long Term Features (Max)\n",
    "sp_state_features_max_temp as (\n",
    "select * from avl_sp_state_lt_max\n",
    "),\n",
    "\n",
    "sp_state_features_max as (\n",
    "SELECT sp_id, event_timestamp,\n",
    "find_loads,\n",
    "indent_click,\n",
    "select_truck_type,\n",
    "book_load,\n",
    "bid,\n",
    "call,\n",
    "confirm_booking,\n",
    "search\n",
    "FROM\n",
    "(\n",
    "SELECT t.sp_id, t.event_timestamp,\n",
    "t.find_loads,\n",
    "t.indent_click,\n",
    "t.select_truck_type,\n",
    "t.book_load,\n",
    "t.bid,\n",
    "t.call,\n",
    "t.confirm_booking,\n",
    "t.search,\n",
    "ROW_NUMBER() OVER (PARTITION BY sp_id, event_timestamp\n",
    "              ORDER BY created_timestamp DESC) AS rnk\n",
    "FROM sp_state_features_max_temp t\n",
    ") \n",
    "WHERE rnk = 1\n",
    "),\n",
    "\n",
    "\n",
    "\n",
    "---- Get the latest long term features from district w.r.t output entities\n",
    "lt_features_d as (\n",
    "select id,\n",
    "find_loads,\n",
    "indent_click,\n",
    "select_truck_type,\n",
    "book_load,\n",
    "bid,\n",
    "call,\n",
    "confirm_booking,\n",
    "search\n",
    "from\n",
    "(\n",
    "select t.*,\n",
    "d.event_timestamp as event_timestamp_lt,\n",
    "d.find_loads,\n",
    "d.indent_click,\n",
    "d.select_truck_type,\n",
    "d.book_load,\n",
    "d.bid,\n",
    "d.call,\n",
    "d.confirm_booking,\n",
    "d.search,\n",
    "ROW_NUMBER() OVER (PARTITION BY t.id, t.sp_id, t.district_id, t.event_timestamp ORDER BY d.event_timestamp DESC) AS rnk\n",
    "from output t\n",
    "left join sp_district_features d on d.sp_id = t.sp_id and d.district_id = t.district_id\n",
    "where d.event_timestamp<t.event_timestamp\n",
    "order by t.sp_id, t.district_id, t.event_timestamp, d.event_timestamp\n",
    ")\n",
    "where rnk=1\n",
    "),\n",
    "\n",
    "\n",
    "\n",
    "lt_features_max_d as (\n",
    "select id,\n",
    "find_loads,\n",
    "indent_click,\n",
    "select_truck_type,\n",
    "book_load,\n",
    "bid,\n",
    "call,\n",
    "confirm_booking,\n",
    "search\n",
    "from\n",
    "(\n",
    "select t.*,\n",
    "d.event_timestamp as event_timestamp_lt,\n",
    "d.find_loads,\n",
    "d.indent_click,\n",
    "d.select_truck_type,\n",
    "d.book_load,\n",
    "d.bid,\n",
    "d.call,\n",
    "d.confirm_booking,\n",
    "d.search,\n",
    "ROW_NUMBER() OVER (PARTITION BY t.id, t.sp_id, t.event_timestamp ORDER BY d.event_timestamp DESC) AS rnk\n",
    "from output t\n",
    "left join sp_district_features_max d on d.sp_id = t.sp_id\n",
    "where d.event_timestamp<t.event_timestamp\n",
    ")\n",
    "where rnk=1\n",
    "),\n",
    "\n",
    "\n",
    "\n",
    "---- Get the latest long term features from state w.r.t output entities\n",
    "\n",
    "lt_features_s as (\n",
    "select id,\n",
    "find_loads,\n",
    "indent_click,\n",
    "select_truck_type,\n",
    "book_load,\n",
    "bid,\n",
    "call,\n",
    "confirm_booking,\n",
    "search\n",
    "from\n",
    "(\n",
    "select t.*,\n",
    "d.event_timestamp as event_timestamp_lt,\n",
    "d.find_loads,\n",
    "d.indent_click,\n",
    "d.select_truck_type,\n",
    "d.book_load,\n",
    "d.bid,\n",
    "d.call,\n",
    "d.confirm_booking,\n",
    "d.search,\n",
    "ROW_NUMBER() OVER (PARTITION BY t.id, t.sp_id, t.state_id, t.event_timestamp ORDER BY d.event_timestamp DESC) AS rnk\n",
    "from output t\n",
    "left join sp_state_features d on d.sp_id = t.sp_id and d.state_id = t.state_id\n",
    "where d.event_timestamp<t.event_timestamp\n",
    "order by t.sp_id, t.state_id, t.event_timestamp, d.event_timestamp\n",
    ")\n",
    "where rnk=1\n",
    "),\n",
    "\n",
    "\n",
    "lt_features_max_s as (\n",
    "select id,\n",
    "find_loads,\n",
    "indent_click,\n",
    "select_truck_type,\n",
    "book_load,\n",
    "bid,\n",
    "call,\n",
    "confirm_booking,\n",
    "search\n",
    "from\n",
    "(\n",
    "select t.id,\n",
    "d.event_timestamp as event_timestamp_lt,\n",
    "d.find_loads,\n",
    "d.indent_click,\n",
    "d.select_truck_type,\n",
    "d.book_load,\n",
    "d.bid,\n",
    "d.call,\n",
    "d.confirm_booking,\n",
    "d.search,\n",
    "ROW_NUMBER() OVER (PARTITION BY t.id, t.sp_id, t.event_timestamp ORDER BY d.event_timestamp DESC) AS rnk\n",
    "from output t\n",
    "left join sp_state_features_max d on d.sp_id = t.sp_id\n",
    "where d.event_timestamp<t.event_timestamp\n",
    ")\n",
    "where rnk=1\n",
    "),\n",
    "\n",
    "----- Joining Features\n",
    "lt_features as (\n",
    "select \n",
    "t.*,\n",
    "\n",
    "coalesce(fd.find_loads, 0) as find_loads_d,\n",
    "coalesce(fd.indent_click, 0) as indent_click_d,\n",
    "coalesce(fd.select_truck_type, 0) as select_truck_type_d,\n",
    "coalesce(fd.book_load, 0) as book_load_d,\n",
    "coalesce(fd.bid, 0) as bid_d,\n",
    "coalesce(fd.call, 0) as call_d,\n",
    "coalesce(fd.confirm_booking, 0) as confirm_booking_d,\n",
    "coalesce(fd.search, 0) as search_d,\n",
    "\n",
    "coalesce(fs.find_loads, 0) as find_loads_s,\n",
    "coalesce(fs.indent_click, 0) as indent_click_s,\n",
    "coalesce(fs.select_truck_type, 0) as select_truck_type_s,\n",
    "coalesce(fs.book_load, 0) as book_load_s,\n",
    "coalesce(fs.bid, 0) as bid_s,\n",
    "coalesce(fs.call, 0) as call_s,\n",
    "coalesce(fs.confirm_booking, 0) as confirm_booking_s,\n",
    "coalesce(fs.search, 0) as search_s,\n",
    "\n",
    "coalesce(fmd.find_loads, 0) as find_loads_d_max,\n",
    "coalesce(fmd.indent_click, 0) as indent_click_d_max,\n",
    "coalesce(fmd.select_truck_type, 0) as select_truck_type_d_max,\n",
    "coalesce(fmd.book_load, 0) as book_load_d_max,\n",
    "coalesce(fmd.bid, 0) as bid_d_max,\n",
    "coalesce(fmd.call, 0) as call_d_max,\n",
    "coalesce(fmd.confirm_booking, 0) as confirm_booking_d_max,\n",
    "coalesce(fmd.search, 0) as search_d_max,\n",
    "\n",
    "coalesce(fms.find_loads, 0) as find_loads_s_max,\n",
    "coalesce(fms.indent_click, 0) as indent_click_s_max,\n",
    "coalesce(fms.select_truck_type, 0) as select_truck_type_s_max,\n",
    "coalesce(fms.book_load, 0) as book_load_s_max,\n",
    "coalesce(fms.bid, 0) as bid_s_max,\n",
    "coalesce(fms.call, 0) as call_s_max,\n",
    "coalesce(fms.confirm_booking, 0) as confirm_booking_s_max,\n",
    "coalesce(fms.search, 0) as search_s_max\n",
    "\n",
    "from output t\n",
    "left join lt_features_d fd on fd.id = t.id\n",
    "left join lt_features_s fs on fs.id = t.id\n",
    "\n",
    "left join lt_features_max_d fmd on fmd.id = t.id\n",
    "left join lt_features_max_s fms on fms.id = t.id\n",
    ")\n",
    "\n",
    "select\n",
    "id, sp_id, event_timestamp, district_id, state_id, availability_flag,\n",
    "ARRAY[\n",
    "cast(COALESCE(1000*find_loads_d/NULLIF(find_loads_d_max,0), 0) as int),\n",
    "cast(COALESCE(1000*indent_click_d/NULLIF(indent_click_d_max,0), 0) as int),\n",
    "cast(COALESCE(1000*select_truck_type_d/NULLIF(select_truck_type_d_max,0), 0) as int),\n",
    "cast(COALESCE(1000*book_load_d/NULLIF(book_load_d_max,0), 0) as int),\n",
    "cast(COALESCE(1000*bid_d/NULLIF(bid_d_max,0), 0) as int),\n",
    "cast(COALESCE(1000*call_d/NULLIF(call_d_max,0), 0) as int),\n",
    "cast(COALESCE(1000*confirm_booking_d/NULLIF(confirm_booking_d_max,0), 0) as int),\n",
    "cast(COALESCE(1000*search_d/NULLIF(search_d_max,0), 0) as int),\n",
    "cast(COALESCE(1000*find_loads_s/NULLIF(find_loads_s_max,0), 0) as int),\n",
    "cast(COALESCE(1000*indent_click_s/NULLIF(indent_click_s_max,0), 0) as int),\n",
    "cast(COALESCE(1000*select_truck_type_s/NULLIF(select_truck_type_s_max,0), 0) as int),\n",
    "cast(COALESCE(1000*book_load_s/NULLIF(book_load_s_max,0), 0) as int),\n",
    "cast(COALESCE(1000*bid_s/NULLIF(bid_s_max,0), 0) as int),\n",
    "cast(COALESCE(1000*call_s/NULLIF(call_s_max,0), 0) as int),\n",
    "cast(COALESCE(1000*confirm_booking_s/NULLIF(confirm_booking_s_max,0), 0) as int),\n",
    "cast(COALESCE(1000*search_s/NULLIF(search_s_max,0), 0) as int)\n",
    "] as lt_features\n",
    "from lt_features\n",
    "where\n",
    "(find_loads_d+indent_click_d+select_truck_type_d+book_load_d+bid_d+call_d+confirm_booking_d+search_d+\n",
    "find_loads_s+indent_click_s+select_truck_type_s+book_load_s+bid_s+call_s+confirm_booking_s+search_s)>0\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19155a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_term_features = wr.athena.read_sql_query(query, \n",
    "                                   database = config.feature_db, \n",
    "                                   workgroup = config.work_group,\n",
    "                                   s3_output = config.s3_athena_output\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d009770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80537, 8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e5b25dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80537"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3f2ef7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'sp_id', 'event_timestamp', 'district_id', 'state_id',\n",
       "       'availability_flag', 'lt_features'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_term_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6af0bac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.merge(df, long_term_features[['id', 'lt_features']], how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4b069f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79084, 9)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2cac2e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sp_id</th>\n",
       "      <th>truck_number</th>\n",
       "      <th>event_timestamp</th>\n",
       "      <th>available_flag</th>\n",
       "      <th>district_id</th>\n",
       "      <th>st_features</th>\n",
       "      <th>agg_features</th>\n",
       "      <th>lt_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>236687</td>\n",
       "      <td>2789071</td>\n",
       "      <td>PB29R8591</td>\n",
       "      <td>2021-07-19 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>aa681238548066717696</td>\n",
       "      <td>[[5, 5052, 4431], [5, 4537, 3911], [5, 3217, 2...</td>\n",
       "      <td>[67, 8789, 22, 292]</td>\n",
       "      <td>[242, 256, 122, 166, 0, 484, 166, 272, 819, 71...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3306588</td>\n",
       "      <td>2857174</td>\n",
       "      <td>RJ52GA0530</td>\n",
       "      <td>2021-08-30 10:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>aa681238546812620800</td>\n",
       "      <td>[[21, 967, 971], [-4, 737, 732], [-8, 5329, 53...</td>\n",
       "      <td>[6884, 2874, 7060, 7060]</td>\n",
       "      <td>[1000, 1000, 1000, 1000, 0, 1000, 1000, 1000, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id    sp_id truck_number     event_timestamp  available_flag  \\\n",
       "0   236687  2789071    PB29R8591 2021-07-19 01:00:00               1   \n",
       "1  3306588  2857174   RJ52GA0530 2021-08-30 10:00:00               0   \n",
       "\n",
       "            district_id                                        st_features  \\\n",
       "0  aa681238548066717696  [[5, 5052, 4431], [5, 4537, 3911], [5, 3217, 2...   \n",
       "1  aa681238546812620800  [[21, 967, 971], [-4, 737, 732], [-8, 5329, 53...   \n",
       "\n",
       "               agg_features                                        lt_features  \n",
       "0       [67, 8789, 22, 292]  [242, 256, 122, 166, 0, 484, 166, 272, 819, 71...  \n",
       "1  [6884, 2874, 7060, 7060]  [1000, 1000, 1000, 1000, 0, 1000, 1000, 1000, ...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9c21d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data['available_flag'] = training_data['availability_flag'].apply(lambda x: 1 if x == 'AVAILABLE' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7bb15fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sp_id</th>\n",
       "      <th>truck_number</th>\n",
       "      <th>event_timestamp</th>\n",
       "      <th>available_flag</th>\n",
       "      <th>district_id</th>\n",
       "      <th>st_features</th>\n",
       "      <th>agg_features</th>\n",
       "      <th>lt_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>236687</td>\n",
       "      <td>2789071</td>\n",
       "      <td>PB29R8591</td>\n",
       "      <td>2021-07-19 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>aa681238548066717696</td>\n",
       "      <td>[[5, 5052, 4431], [5, 4537, 3911], [5, 3217, 2...</td>\n",
       "      <td>[67, 8789, 22, 292]</td>\n",
       "      <td>[242, 256, 122, 166, 0, 484, 166, 272, 819, 71...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    sp_id truck_number     event_timestamp  available_flag  \\\n",
       "0  236687  2789071    PB29R8591 2021-07-19 01:00:00               1   \n",
       "\n",
       "            district_id                                        st_features  \\\n",
       "0  aa681238548066717696  [[5, 5052, 4431], [5, 4537, 3911], [5, 3217, 2...   \n",
       "\n",
       "          agg_features                                        lt_features  \n",
       "0  [67, 8789, 22, 292]  [242, 256, 122, 166, 0, 484, 166, 272, 819, 71...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1dd4a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data = training_data[training_data['agg_features'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e335db2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79084, 9)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ebda2441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79084"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "acf433e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5021"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['truck_number'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b10c17da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "566"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['district_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b600ca1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'sp_id', 'truck_number', 'event_timestamp', 'available_flag',\n",
       "       'district_id', 'st_features', 'agg_features'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "47c8c0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[['st_features','available_flag']].to_csv('avail_manifest_v0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b5119f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-11 08:46:00.302364: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/amazon/efa/lib64:/opt/amazon/openmpi/lib64:/usr/local/lib:/usr/lib:/lib:\n",
      "2022-01-11 08:46:00.302396: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers import LSTM, Dropout, Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Embedding,Reshape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dcbf49b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'sp_id', 'truck_number', 'event_timestamp', 'available_flag',\n",
       "       'district_id', 'st_features', 'agg_features', 'lt_features'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "438f7dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sp_id</th>\n",
       "      <th>truck_number</th>\n",
       "      <th>event_timestamp</th>\n",
       "      <th>available_flag</th>\n",
       "      <th>district_id</th>\n",
       "      <th>st_features</th>\n",
       "      <th>agg_features</th>\n",
       "      <th>lt_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>236687</td>\n",
       "      <td>2789071</td>\n",
       "      <td>PB29R8591</td>\n",
       "      <td>2021-07-19 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>aa681238548066717696</td>\n",
       "      <td>[[5, 5052, 4431], [5, 4537, 3911], [5, 3217, 2...</td>\n",
       "      <td>[67, 8789, 22, 292]</td>\n",
       "      <td>[242, 256, 122, 166, 0, 484, 166, 272, 819, 71...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3306588</td>\n",
       "      <td>2857174</td>\n",
       "      <td>RJ52GA0530</td>\n",
       "      <td>2021-08-30 10:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>aa681238546812620800</td>\n",
       "      <td>[[21, 967, 971], [-4, 737, 732], [-8, 5329, 53...</td>\n",
       "      <td>[6884, 2874, 7060, 7060]</td>\n",
       "      <td>[1000, 1000, 1000, 1000, 0, 1000, 1000, 1000, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id    sp_id truck_number     event_timestamp  available_flag  \\\n",
       "0   236687  2789071    PB29R8591 2021-07-19 01:00:00               1   \n",
       "1  3306588  2857174   RJ52GA0530 2021-08-30 10:00:00               0   \n",
       "\n",
       "            district_id                                        st_features  \\\n",
       "0  aa681238548066717696  [[5, 5052, 4431], [5, 4537, 3911], [5, 3217, 2...   \n",
       "1  aa681238546812620800  [[21, 967, 971], [-4, 737, 732], [-8, 5329, 53...   \n",
       "\n",
       "               agg_features                                        lt_features  \n",
       "0       [67, 8789, 22, 292]  [242, 256, 122, 166, 0, 484, 166, 272, 819, 71...  \n",
       "1  [6884, 2874, 7060, 7060]  [1000, 1000, 1000, 1000, 0, 1000, 1000, 1000, ...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d0a9a7ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([   5, 5052, 4431], dtype=int32),\n",
       "       array([   5, 4537, 3911], dtype=int32),\n",
       "       array([   5, 3217, 2794], dtype=int32),\n",
       "       array([   5, 1777, 1409], dtype=int32),\n",
       "       array([  5, 337, 176], dtype=int32)], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['st_features'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b8f4ffe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79084, 9)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ba4e5f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-11 08:46:08.295332: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-01-11 08:46:08.295398: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-16-42-212): /proc/driver/nvidia/version does not exist\n",
      "2022-01-11 08:46:08.298706: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "output = np.array(training_data.available_flag.to_list())\n",
    "output = tf.convert_to_tensor(output, np.int8)\n",
    "\n",
    "### LSTM Features\n",
    "st_features = []\n",
    "for i in training_data.st_features.to_list():\n",
    "    i = i.tolist()\n",
    "    k = []\n",
    "    for j in i:\n",
    "        k.append(j.tolist())\n",
    "    st_features.append(k)\n",
    "\n",
    "st_features = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    st_features, maxlen=5,padding=\"post\"\n",
    ")\n",
    "\n",
    "st_features = tf.convert_to_tensor(st_features, np.int8)\n",
    "\n",
    "\n",
    "### Long Term Features\n",
    "lt_features = []\n",
    "for i in training_data.lt_features.to_list():\n",
    "    i = i.tolist()\n",
    "    lt_features.append(i)\n",
    "    \n",
    "lt_features = tf.convert_to_tensor(lt_features, np.int8)\n",
    "\n",
    "## agg features\n",
    "\n",
    "\n",
    "\n",
    "agg_features = []\n",
    "for i in training_data.agg_features.to_list():\n",
    "    i = i.tolist()\n",
    "    agg_features.append(i)\n",
    "    \n",
    "agg_features = tf.convert_to_tensor(agg_features, np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c22b2a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gps_characteristics = []\n",
    "\n",
    "# for i in range(len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "208ecac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def Find_Optimal_Cutoff(target, predicted):\n",
    "    fpr, tpr, threshold = roc_curve(target, predicted)\n",
    "    i = np.arange(len(tpr)) \n",
    "    roc = pd.DataFrame({'tf' : pd.Series(tpr-(1-fpr), index=i), 'threshold' : pd.Series(threshold, index=i)})\n",
    "    roc_t = roc.iloc[(roc.tf-0).abs().argsort()[:1]]\n",
    "\n",
    "    return list(roc_t['threshold']) \n",
    "\n",
    "class prediction_history(Callback):\n",
    "    def __init__(self):\n",
    "        self.predhis = []\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.predhis.append(model.predict([x_test]))\n",
    "\n",
    "predictions=prediction_history()\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=4, min_delta=0)\n",
    "bst_model_path =  'truck_availability_model.h5'\n",
    "model_checkpoint = ModelCheckpoint(bst_model_path, save_best_only=True, save_weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0ec43060",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timesteps = st_features.shape[1]\n",
    "n_features = st_features.shape[2]\n",
    "n_lt_features = lt_features.shape[1]\n",
    "n_agg_features = agg_features.shape[1]\n",
    "# n_agg_features = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b6cdc218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80537, 8), (3956015, 7))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape,long_term_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e24292ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_speed_agg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "549df90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)           [(None, 5, 3)]       0           []                               \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  (None, 200)          163200      ['input_7[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 200)          0           ['lstm_2[0][0]']                 \n",
      "                                                                                                  \n",
      " input_8 (InputLayer)           [(None, 16)]         0           []                               \n",
      "                                                                                                  \n",
      " input_9 (InputLayer)           [(None, 4)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 220)          0           ['dropout_2[0][0]',              \n",
      "                                                                  'input_8[0][0]',                \n",
      "                                                                  'input_9[0][0]']                \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 256)          56576       ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 128)          32896       ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 64)           8256        ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 1)            65          ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 260,993\n",
      "Trainable params: 260,993\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ts_input = Input(shape=(n_timesteps,n_features))\n",
    "main_input_lstm = LSTM(200, activation='relu')(ts_input)\n",
    "st_input = Dropout(0.5)(main_input_lstm)\n",
    "\n",
    "lt_input = Input(shape=(n_lt_features,))\n",
    "agg_input = Input(shape=(n_agg_features,))\n",
    "merged = tf.keras.layers.Concatenate(axis=1)([st_input, lt_input,agg_input])\n",
    "\n",
    "\n",
    "x = Dense(256, activation='relu')(merged)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "main_output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=[ts_input,lt_input,agg_input], outputs= [main_output])\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a011ee0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79084, 9)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9c0e05a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79084"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eea1ae95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(st_features, output, \n",
    "#           epochs=30,  batch_size=1024, \n",
    "#           verbose = True, validation_split=0.2,\n",
    "#           callbacks=[model_checkpoint, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a8111b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7298fe4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d4f96af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_input = Input(shape=(n_timesteps,n_features))\n",
    "# main_input_lstm = LSTM(200, activation='relu')(ts_input)\n",
    "# st_input = Dropout(0.5)(main_input_lstm)\n",
    "\n",
    "# lt_input = Input(shape=(n_lt_features,))\n",
    "\n",
    "# merged = tf.keras.layers.Concatenate(axis=1)([st_input, lt_input])\n",
    "\n",
    "# x = Dense(256, activation='relu')(merged)\n",
    "# x = Dense(128, activation='relu')(x)\n",
    "# x = Dense(64, activation='relu')(x)\n",
    "# main_output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# model = Model(inputs=[ts_input, lt_input], outputs= [main_output])\n",
    "\n",
    "# model.compile(optimizer=Adam(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ac74b66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "58/58 [==============================] - 8s 119ms/step - loss: 1.0359 - accuracy: 0.5733 - val_loss: 0.6948 - val_accuracy: 0.6065\n",
      "Epoch 2/50\n",
      "58/58 [==============================] - 7s 115ms/step - loss: 0.6614 - accuracy: 0.6363 - val_loss: 0.6402 - val_accuracy: 0.6548\n",
      "Epoch 3/50\n",
      "58/58 [==============================] - 7s 115ms/step - loss: 0.6146 - accuracy: 0.6752 - val_loss: 0.6225 - val_accuracy: 0.6706\n",
      "Epoch 4/50\n",
      "58/58 [==============================] - 7s 117ms/step - loss: 0.5942 - accuracy: 0.6923 - val_loss: 0.6135 - val_accuracy: 0.6783\n",
      "Epoch 5/50\n",
      "58/58 [==============================] - 7s 116ms/step - loss: 0.5791 - accuracy: 0.7032 - val_loss: 0.6106 - val_accuracy: 0.6831\n",
      "Epoch 6/50\n",
      "58/58 [==============================] - 7s 117ms/step - loss: 0.5661 - accuracy: 0.7119 - val_loss: 0.6116 - val_accuracy: 0.6825\n",
      "Epoch 7/50\n",
      "58/58 [==============================] - 7s 118ms/step - loss: 0.5530 - accuracy: 0.7218 - val_loss: 0.6101 - val_accuracy: 0.6829\n",
      "Epoch 8/50\n",
      "58/58 [==============================] - 7s 117ms/step - loss: 0.5432 - accuracy: 0.7279 - val_loss: 0.6165 - val_accuracy: 0.6825\n",
      "Epoch 9/50\n",
      "58/58 [==============================] - 7s 117ms/step - loss: 0.5309 - accuracy: 0.7368 - val_loss: 0.6089 - val_accuracy: 0.6894\n",
      "Epoch 10/50\n",
      "58/58 [==============================] - 7s 116ms/step - loss: 0.5208 - accuracy: 0.7436 - val_loss: 0.6097 - val_accuracy: 0.6866\n",
      "Epoch 11/50\n",
      "58/58 [==============================] - 7s 116ms/step - loss: 0.5079 - accuracy: 0.7514 - val_loss: 0.6160 - val_accuracy: 0.6837\n",
      "Epoch 12/50\n",
      "58/58 [==============================] - 7s 117ms/step - loss: 0.5004 - accuracy: 0.7560 - val_loss: 0.6161 - val_accuracy: 0.6834\n",
      "Epoch 13/50\n",
      "58/58 [==============================] - 7s 120ms/step - loss: 0.4854 - accuracy: 0.7668 - val_loss: 0.6247 - val_accuracy: 0.6829\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7317f7a0d0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([st_features, lt_features,agg_features], output, \n",
    "          epochs=50,  batch_size=1024, \n",
    "          verbose = True, validation_split=0.25,\n",
    "          callbacks=[model_checkpoint, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "780cbeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['sp_id']==3178051].to_csv('one_sp_val_sample.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0d7b2aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(features_list),len(features_list[0]),len(features_list[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c06efac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6fe142ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_list = np.array(sequences_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2bb051ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20337*25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e3e818f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_list = np.reshape(features_list,( features_list.shape[0],features_list.shape[1],4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8e8f9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_list=np.array(features_list).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aad4f2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# tf.convert_to_tensor(features_list, dtype=tf.int32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e792cb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (features_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "54468af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit([features_list[:int(len(features_list)*.8)]], output[:int(len(features_list)*.8)], epochs=10,batch_size=10,\n",
    "#           validation_data = ([features_list[int(len(features_list)*.8):]], output[int(len(features_list)*.8):]),\n",
    "#           verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3f8fd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Custom (feature_store)",
   "language": "python",
   "name": "feature_store"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
