{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8347fc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dateutil.tz\n",
    "import datetime as dt\n",
    "import json\n",
    "import awswrangler as wr\n",
    "from feature_store import feature_store\n",
    "from feature_store.feature_table import feature_table\n",
    "from feature_store.value_type import ValueType\n",
    "import feature_store.config as config\n",
    "from io import StringIO\n",
    "import urllib3\n",
    "import logging\n",
    "import sys\n",
    "from json import dumps\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "def get_ymd(datetime):\n",
    "    year = datetime.year\n",
    "    month = datetime.month\n",
    "    day = datetime.day\n",
    "            \n",
    "    if month < 10:\n",
    "        month = '0' + str(month)\n",
    "    if day < 10:\n",
    "        day = '0' + str(day)\n",
    "    return year, month, day\n",
    "\n",
    "def first_day_next_month(date):\n",
    "    return (date.replace(day=1) + dt.timedelta(days=32)).replace(day=1)\n",
    "\n",
    "def last_second_of_month(date: str) -> str:\n",
    "    return str((pd.Timestamp(date) + pd.offsets.MonthEnd(0)).date()) + \" 23:59:59\"\n",
    "\n",
    "def first_second_of_month(date: str) -> str:\n",
    "    return str((pd.Timestamp(date) + pd.offsets.MonthBegin(0)).date()) + \" 00:00:00\"\n",
    "\n",
    "streamer = StringIO()\n",
    "\n",
    "def setup_logging():\n",
    "    logger = logging.getLogger()\n",
    "    for h in logger.handlers:\n",
    "        logger.removeHandler(h)\n",
    "     \n",
    "    h = logging.StreamHandler(stream = streamer)\n",
    "    h.setFormatter(logging.Formatter(\"%(asctime)s %(levelname)s: %(message)s\",\n",
    "                              \"%Y-%m-%d %H:%M:%S\"))\n",
    "    logger.addHandler(h)\n",
    "    logger.setLevel(logging.INFO)\n",
    "    return logger\n",
    "\n",
    "def query_log(query_id, table, logger):\n",
    "    status = wr.athena.get_query_execution(query_id)['Status']['State']\n",
    "    if wr.athena.get_query_execution(query_id)['Status']['State'] in ['FAILED', 'CANCELLED']:\n",
    "        logger.critical(table + ': query is in ' + status + ' State. ' + 'QueryID: ' + query_id)\n",
    "    else:\n",
    "        logger.info(table + ': query is in ' + status + ' State. ' + 'QueryID: ' + query_id)\n",
    "    return None\n",
    "\n",
    "http = urllib3.PoolManager()\n",
    "url = 'https://chat.googleapis.com/v1/spaces/AAAALuxU48o/messages?key=AIzaSyDdI0hCZtE6vySjMm-WEfRq3CPzqKqqsHI&token=T1j8SVrn051V2f9q0wxFMbbI5DkIH2IKTxPYy3TnP9Q%3D'\n",
    "fs = feature_store.feature_store()\n",
    "\n",
    "zone = dateutil.tz.gettz('Asia/Calcutta')\n",
    "\n",
    "logger = setup_logging()\n",
    "\n",
    "now = dt.datetime.now(zone)\n",
    "current_hour = now.replace(minute=0, second=0, microsecond=0)\n",
    "current_hour_s = current_hour.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "def query_progress(query_id, run_async, table_name):\n",
    "    if not run_async:\n",
    "            status = wr.athena.get_query_execution(query_id)['Status']['State']\n",
    "            while status not in ('SUCCEEDED'):\n",
    "                if status in ['RUNNING', 'QUEUED']:\n",
    "                    status = wr.athena.get_query_execution(query_id)['Status']['State']\n",
    "                elif status == 'FAILED':\n",
    "                    print('Query Failed')\n",
    "                    break\n",
    "                elif status == 'CANCELLED':\n",
    "                    print('Query Cancelled')\n",
    "                    break\n",
    "    else:\n",
    "        status = wr.athena.get_query_execution(query_id)['Status']['State']\n",
    "        while status not in ('RUNNING'):\n",
    "            if status == 'QUEUED':\n",
    "                time.sleep(2)\n",
    "                status = wr.athena.get_query_execution(query_id)['Status']['State']\n",
    "            elif status == 'SUCCEEDED':\n",
    "                print('Query Succeeded')\n",
    "                break\n",
    "            elif status == 'FAILED':\n",
    "                print('Query Failed')\n",
    "                break\n",
    "            elif status == 'CANCELLED':\n",
    "                print('Query Cancelled')\n",
    "                break\n",
    "    query_log(query_id, table_name, logger)\n",
    "    return status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13cc6584",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''with sp_mapping_temp as (\n",
    "SELECT  id as fleet_owner_id, max_by(cast(phone_no as varchar), updated_at) as mobile_no,\n",
    "max_by(cast(iam_id as int), updated_at) as sp_id  FROM  \"awsdatacatalog\".\"supply_team\".\"supply_team_blackbuck_fleetapp_fleetowner\"\n",
    "group by 1\n",
    "),\n",
    "\n",
    "sp_mapping as (\n",
    "select fleet_owner_id, mobile_no, cast(sp_id as bigint) as sp_id \n",
    "from sp_mapping_temp \n",
    "where mobile_no in (\n",
    "select mobile_no from (\n",
    "select mobile_no, count(*) as sp_count from sp_mapping_temp\n",
    "group by 1\n",
    "having count(*)<=1))\n",
    "),\n",
    "\n",
    "--- Truck Mapping to SP ID\n",
    "truck_mapping as (\n",
    "select ft.id as truck_id,\n",
    "ft.truck_no as truck_number,\n",
    "tor.fleet_owner_id as fleet_owner_id,\n",
    "s.sp_id\n",
    "from \"awsdatacatalog\".\"supply_team\".\"supply_team_blackbuck_fleetapp_truck\" ft\n",
    "inner join \"awsdatacatalog\".\"supply_team\".\"supply_team_blackbuck_truck_owner_request\" tor on ft.id = tor.truck_id\n",
    "inner join sp_mapping s on s.fleet_owner_id = tor.fleet_owner_id\n",
    "where \n",
    "ft.truck_no != ''\n",
    "and tor.fleet_owner_id is not null\n",
    "and tor.kyc_status_v2 ='APPROVED'\n",
    "and ft.is_truck = 'VERIFIED'\n",
    "and ft.is_verified != 3\n",
    "group by 1,2,3,4\n",
    "),\n",
    "\n",
    "--- Single Truck FOs/SPs\n",
    "single_truck_sps as (\n",
    "select\n",
    "tm.*,\n",
    "tmc.number_of_trucks\n",
    "from truck_mapping tm\n",
    "left join (select sp_id, count(distinct truck_number) as number_of_trucks from truck_mapping group by 1) tmc on tmc.sp_id = tm.sp_id\n",
    "where tmc.number_of_trucks = 1\n",
    "),\n",
    "\n",
    "------ Plaza to District Mapping\n",
    "district_boundaries as (\n",
    "select place_id as district_id, \n",
    "name as district_name, \n",
    "ST_GeomFromBinary(from_hex(to_utf8(replace(boundary_geog,'20E61000')))) as boundary_geog,\n",
    "ST_X(ST_Centroid(ST_GeomFromBinary(from_hex(to_utf8(replace(boundary_geog,'20E61000')))))) as longitude,\n",
    "ST_Y(ST_Centroid(ST_GeomFromBinary(from_hex(to_utf8(replace(boundary_geog,'20E61000')))))) as latitude\n",
    "from location_service.public.admin_area where deleted = false\n",
    "and local_tag = 'DISTRICT'\n",
    "and boundary_geog != ''\n",
    "),\n",
    "\n",
    "distict_distance as (\n",
    "select a.district_id as from_district_id,\n",
    "b.district_id as to_district_id,\n",
    "cast(great_circle_distance(a.latitude, a.longitude, b.latitude, b.longitude) as int) as distance\n",
    "from district_boundaries a\n",
    "cross join district_boundaries b\n",
    "),\n",
    "\n",
    "---- Semantics District Vectors\n",
    "semantics_score_district_temp as (\n",
    "\tSELECT *\n",
    "\tFROM (\n",
    "\t\t\tSELECT t.*,\n",
    "\t\t\t\tROW_NUMBER() OVER (\n",
    "\t\t\t\t\tPARTITION BY bb_place_id\n",
    "\t\t\t\t\tORDER BY created_timestamp DESC\n",
    "\t\t\t\t) AS rnk\n",
    "\t\t\tFROM \"awsdatacatalog\".\"feature_store\".\"semantics_from_district\" t\n",
    "\t\t)\n",
    "\tWHERE rnk = 1\n",
    "),\n",
    "\n",
    "semantics_score_district_map as (\n",
    "\tselect bb_place_id as district_id,\n",
    "\t\tMAP_FROM_ENTRIES(\n",
    "\t\t\tARRAY [ ('f_1', f_1),\n",
    "\t\t\t('f_2', f_2),\n",
    "\t\t\t('f_3', f_3),\n",
    "\t\t\t('f_4', f_4),\n",
    "\t\t\t('f_5', f_5),\n",
    "\t\t\t('f_6', f_6),\n",
    "\t\t\t('f_7', f_7),\n",
    "\t\t\t('f_8', f_8),\n",
    "\t\t\t('f_9', f_9),\n",
    "\t\t\t('f_10', f_10),\n",
    "\t\t\t('f_11', f_11),\n",
    "\t\t\t('f_12', f_12),\n",
    "\t\t\t('f_13', f_13),\n",
    "\t\t\t('f_14', f_14),\n",
    "\t\t\t('f_15', f_15),\n",
    "\t\t\t('f_16', f_16),\n",
    "\t\t\t('f_17', f_17),\n",
    "\t\t\t('f_18', f_18),\n",
    "\t\t\t('f_19', f_19),\n",
    "\t\t\t('f_20', f_20),\n",
    "\t\t\t('f_21', f_21),\n",
    "\t\t\t('f_22', f_22),\n",
    "\t\t\t('f_23', f_23),\n",
    "\t\t\t('f_24', f_24),\n",
    "\t\t\t('f_25', f_25),\n",
    "\t\t\t('f_26', f_26),\n",
    "\t\t\t('f_27', f_27),\n",
    "\t\t\t('f_28', f_28),\n",
    "\t\t\t('f_29', f_29),\n",
    "\t\t\t('f_30', f_30),\n",
    "\t\t\t('f_31', f_31),\n",
    "\t\t\t('f_32', f_32),\n",
    "\t\t\t('f_33', f_33),\n",
    "\t\t\t('f_34', f_34),\n",
    "\t\t\t('f_35', f_35),\n",
    "\t\t\t('f_36', f_36),\n",
    "\t\t\t('f_37', f_37),\n",
    "\t\t\t('f_38', f_38),\n",
    "\t\t\t('f_39', f_39),\n",
    "\t\t\t('f_40', f_40),\n",
    "\t\t\t('f_41', f_41),\n",
    "\t\t\t('f_42', f_42),\n",
    "\t\t\t('f_43', f_43),\n",
    "\t\t\t('f_44', f_44),\n",
    "\t\t\t('f_45', f_45),\n",
    "\t\t\t('f_46', f_46),\n",
    "\t\t\t('f_47', f_47),\n",
    "\t\t\t('f_48', f_48),\n",
    "\t\t\t('f_49', f_49),\n",
    "\t\t\t('f_50', f_50),\n",
    "\t\t\t('f_51', f_51),\n",
    "\t\t\t('f_52', f_52),\n",
    "\t\t\t('f_53', f_53),\n",
    "\t\t\t('f_54', f_54),\n",
    "\t\t\t('f_55', f_55),\n",
    "\t\t\t('f_56', f_56),\n",
    "\t\t\t('f_57', f_57),\n",
    "\t\t\t('f_58', f_58),\n",
    "\t\t\t('f_59', f_59),\n",
    "\t\t\t('f_60', f_60),\n",
    "\t\t\t('f_61', f_61),\n",
    "\t\t\t('f_62', f_62),\n",
    "\t\t\t('f_63', f_63),\n",
    "\t\t\t('f_64', f_64),\n",
    "\t\t\t('f_65', f_65),\n",
    "\t\t\t('f_66', f_66),\n",
    "\t\t\t('f_67', f_67),\n",
    "\t\t\t('f_68', f_68),\n",
    "\t\t\t('f_69', f_69),\n",
    "\t\t\t('f_70', f_70),\n",
    "\t\t\t('f_71', f_71),\n",
    "\t\t\t('f_72', f_72),\n",
    "\t\t\t('f_73', f_73),\n",
    "\t\t\t('f_74', f_74),\n",
    "\t\t\t('f_75', f_75),\n",
    "\t\t\t('f_76', f_76),\n",
    "\t\t\t('f_77', f_77),\n",
    "\t\t\t('f_78', f_78),\n",
    "\t\t\t('f_79', f_79),\n",
    "\t\t\t('f_80', f_80),\n",
    "\t\t\t('f_81', f_81),\n",
    "\t\t\t('f_82', f_82),\n",
    "\t\t\t('f_83', f_83),\n",
    "\t\t\t('f_84', f_84),\n",
    "\t\t\t('f_85', f_85),\n",
    "\t\t\t('f_86', f_86),\n",
    "\t\t\t('f_87', f_87),\n",
    "\t\t\t('f_88', f_88),\n",
    "\t\t\t('f_89', f_89),\n",
    "\t\t\t('f_90', f_90),\n",
    "\t\t\t('f_91', f_91),\n",
    "\t\t\t('f_92', f_92),\n",
    "\t\t\t('f_93', f_93),\n",
    "\t\t\t('f_94', f_94),\n",
    "\t\t\t('f_95', f_95),\n",
    "\t\t\t('f_96', f_96),\n",
    "\t\t\t('f_97', f_97),\n",
    "\t\t\t('f_98', f_98),\n",
    "\t\t\t('f_99', f_99),\n",
    "\t\t\t('f_100', f_100),\n",
    "\t\t\t('f_101', f_101),\n",
    "\t\t\t('f_102', f_102),\n",
    "\t\t\t('f_103', f_103),\n",
    "\t\t\t('f_104', f_104),\n",
    "\t\t\t('f_105', f_105),\n",
    "\t\t\t('f_106', f_106),\n",
    "\t\t\t('f_107', f_107),\n",
    "\t\t\t('f_108', f_108),\n",
    "\t\t\t('f_109', f_109),\n",
    "\t\t\t('f_110', f_110),\n",
    "\t\t\t('f_111', f_111),\n",
    "\t\t\t('f_112', f_112),\n",
    "\t\t\t('f_113', f_113),\n",
    "\t\t\t('f_114', f_114),\n",
    "\t\t\t('f_115', f_115),\n",
    "\t\t\t('f_116', f_116),\n",
    "\t\t\t('f_117', f_117),\n",
    "\t\t\t('f_118', f_118),\n",
    "\t\t\t('f_119', f_119),\n",
    "\t\t\t('f_120', f_120),\n",
    "\t\t\t('f_121', f_121),\n",
    "\t\t\t('f_122', f_122),\n",
    "\t\t\t('f_123', f_123),\n",
    "\t\t\t('f_124', f_124),\n",
    "\t\t\t('f_125', f_125),\n",
    "\t\t\t('f_126', f_126),\n",
    "\t\t\t('f_127', f_127),\n",
    "\t\t\t('f_128', f_128),\n",
    "\t\t\t('f_129', f_129),\n",
    "\t\t\t('f_130', f_130),\n",
    "\t\t\t('f_131', f_131),\n",
    "\t\t\t('f_132', f_132),\n",
    "\t\t\t('f_133', f_133),\n",
    "\t\t\t('f_134', f_134),\n",
    "\t\t\t('f_135', f_135),\n",
    "\t\t\t('f_136', f_136),\n",
    "\t\t\t('f_137', f_137),\n",
    "\t\t\t('f_138', f_138),\n",
    "\t\t\t('f_139', f_139),\n",
    "\t\t\t('f_140', f_140),\n",
    "\t\t\t('f_141', f_141),\n",
    "\t\t\t('f_142', f_142),\n",
    "\t\t\t('f_143', f_143),\n",
    "\t\t\t('f_144', f_144),\n",
    "\t\t\t('f_145', f_145),\n",
    "\t\t\t('f_146', f_146),\n",
    "\t\t\t('f_147', f_147),\n",
    "\t\t\t('f_148', f_148),\n",
    "\t\t\t('f_149', f_149),\n",
    "\t\t\t('f_150', f_150),\n",
    "\t\t\t('f_151', f_151),\n",
    "\t\t\t('f_152', f_152),\n",
    "\t\t\t('f_153', f_153),\n",
    "\t\t\t('f_154', f_154),\n",
    "\t\t\t('f_155', f_155),\n",
    "\t\t\t('f_156', f_156),\n",
    "\t\t\t('f_157', f_157),\n",
    "\t\t\t('f_158', f_158),\n",
    "\t\t\t('f_159', f_159),\n",
    "\t\t\t('f_160', f_160),\n",
    "\t\t\t('f_161', f_161),\n",
    "\t\t\t('f_162', f_162),\n",
    "\t\t\t('f_163', f_163),\n",
    "\t\t\t('f_164', f_164),\n",
    "\t\t\t('f_165', f_165),\n",
    "\t\t\t('f_166', f_166),\n",
    "\t\t\t('f_167', f_167),\n",
    "\t\t\t('f_168', f_168),\n",
    "\t\t\t('f_169', f_169),\n",
    "\t\t\t('f_170', f_170),\n",
    "\t\t\t('f_171', f_171),\n",
    "\t\t\t('f_172', f_172),\n",
    "\t\t\t('f_173', f_173),\n",
    "\t\t\t('f_174', f_174),\n",
    "\t\t\t('f_175', f_175),\n",
    "\t\t\t('f_176', f_176),\n",
    "\t\t\t('f_177', f_177),\n",
    "\t\t\t('f_178', f_178),\n",
    "\t\t\t('f_179', f_179),\n",
    "\t\t\t('f_180', f_180),\n",
    "\t\t\t('f_181', f_181),\n",
    "\t\t\t('f_182', f_182),\n",
    "\t\t\t('f_183', f_183),\n",
    "\t\t\t('f_184', f_184),\n",
    "\t\t\t('f_185', f_185),\n",
    "\t\t\t('f_186', f_186),\n",
    "\t\t\t('f_187', f_187),\n",
    "\t\t\t('f_188', f_188),\n",
    "\t\t\t('f_189', f_189),\n",
    "\t\t\t('f_190', f_190),\n",
    "\t\t\t('f_191', f_191),\n",
    "\t\t\t('f_192', f_192),\n",
    "\t\t\t('f_193', f_193),\n",
    "\t\t\t('f_194', f_194),\n",
    "\t\t\t('f_195', f_195),\n",
    "\t\t\t('f_196', f_196),\n",
    "\t\t\t('f_197', f_197),\n",
    "\t\t\t('f_198', f_198),\n",
    "\t\t\t('f_199', f_199),\n",
    "\t\t\t('f_200', f_200),\n",
    "\t\t\t('f_201', f_201),\n",
    "\t\t\t('f_202', f_202),\n",
    "\t\t\t('f_203', f_203),\n",
    "\t\t\t('f_204', f_204),\n",
    "\t\t\t('f_205', f_205),\n",
    "\t\t\t('f_206', f_206),\n",
    "\t\t\t('f_207', f_207),\n",
    "\t\t\t('f_208', f_208),\n",
    "\t\t\t('f_209', f_209),\n",
    "\t\t\t('f_210', f_210),\n",
    "\t\t\t('f_211', f_211),\n",
    "\t\t\t('f_212', f_212),\n",
    "\t\t\t('f_213', f_213),\n",
    "\t\t\t('f_214', f_214),\n",
    "\t\t\t('f_215', f_215),\n",
    "\t\t\t('f_216', f_216),\n",
    "\t\t\t('f_217', f_217),\n",
    "\t\t\t('f_218', f_218),\n",
    "\t\t\t('f_219', f_219),\n",
    "\t\t\t('f_220', f_220),\n",
    "\t\t\t('f_221', f_221),\n",
    "\t\t\t('f_222', f_222),\n",
    "\t\t\t('f_223', f_223),\n",
    "\t\t\t('f_224', f_224),\n",
    "\t\t\t('f_225', f_225),\n",
    "\t\t\t('f_226', f_226),\n",
    "\t\t\t('f_227', f_227),\n",
    "\t\t\t('f_228', f_228),\n",
    "\t\t\t('f_229', f_229),\n",
    "\t\t\t('f_230', f_230),\n",
    "\t\t\t('f_231', f_231),\n",
    "\t\t\t('f_232', f_232),\n",
    "\t\t\t('f_233', f_233),\n",
    "\t\t\t('f_234', f_234),\n",
    "\t\t\t('f_235', f_235),\n",
    "\t\t\t('f_236', f_236),\n",
    "\t\t\t('f_237', f_237),\n",
    "\t\t\t('f_238', f_238),\n",
    "\t\t\t('f_239', f_239),\n",
    "\t\t\t('f_240', f_240),\n",
    "\t\t\t('f_241', f_241),\n",
    "\t\t\t('f_242', f_242),\n",
    "\t\t\t('f_243', f_243),\n",
    "\t\t\t('f_244', f_244),\n",
    "\t\t\t('f_245', f_245),\n",
    "\t\t\t('f_246', f_246),\n",
    "\t\t\t('f_247', f_247),\n",
    "\t\t\t('f_248', f_248),\n",
    "\t\t\t('f_249', f_249),\n",
    "\t\t\t('f_250', f_250) ]\n",
    "\t\t) as features,\n",
    "\t\t1 as key\n",
    "\tfrom semantics_score_district_temp\n",
    "),\n",
    "\n",
    "district_similarity as (\n",
    "select a.district_id as from_district_id,\n",
    "\tb.district_id as to_district_id,\n",
    "\tcast(\n",
    "\t\tround(cosine_similarity(a.features, b.features), 2) * 100 as int\n",
    "\t) as similarity\n",
    "from semantics_score_district_map a\n",
    "\tleft join semantics_score_district_map b on a.key = b.key\n",
    "group by 1, 2, 3\n",
    "),\n",
    "\n",
    "output as (\n",
    "select * from awsdatacatalog.feature_store.avl_training_output_v2\n",
    "where sp_id in (select sp_id from single_truck_sps)\n",
    "and district_id in (select district_id from district_boundaries)\n",
    "),\n",
    "--- Merge Output with GPS Transactions data\n",
    "gps_merge_temp as (\n",
    "select o.*,\n",
    "s.truck_number,\n",
    "gps.entity as district_id_gps,\n",
    "gps.event_timestamp as event_timestamp_gps,\n",
    "gps.total_dwell_time,\n",
    "gps.total_speed,\n",
    "gps.total_is_ignition_off,\n",
    "gps.total_records,\n",
    "d.distance,\n",
    "\n",
    "case\n",
    "    when gps.entity = LAG(gps.entity, 1) OVER (PARTITION BY o.id ORDER BY gps.event_timestamp DESC) then 0\n",
    "\n",
    "    else 1\n",
    "end as flag,\n",
    "date_diff('day',gps.event_timestamp,o.event_timestamp) as time_diff,\n",
    "case\n",
    "    when date_diff('day',gps.event_timestamp,o.event_timestamp)<=1 then 'day_1'\n",
    "     when date_diff('day',gps.event_timestamp,o.event_timestamp)<=2 and date_diff('day',gps.event_timestamp,o.event_timestamp)>1 then 'day_2'\n",
    "     when date_diff('day',gps.event_timestamp,o.event_timestamp)<=3 and date_diff('day',gps.event_timestamp,o.event_timestamp)>2 then 'day_3'\n",
    "     when date_diff('day',gps.event_timestamp,o.event_timestamp)<=4 and date_diff('day',gps.event_timestamp,o.event_timestamp)>3 then 'day_4'\n",
    "     when date_diff('day',gps.event_timestamp,o.event_timestamp)<=5 and date_diff('day',gps.event_timestamp,o.event_timestamp)>4 then 'day_5'\n",
    "    else 'others'\n",
    "end as day_flag\n",
    "\n",
    "from output o\n",
    "inner join single_truck_sps s on s.sp_id = o.sp_id\n",
    "inner join gps_features_district gps on s.truck_number = gps.truck_number and o.event_timestamp>gps.event_timestamp and gps.event_timestamp>=o.event_timestamp - interval '5' day\n",
    "inner join distict_distance d on d.from_district_id = o.district_id and d.to_district_id = gps.entity\n",
    "),\n",
    "\n",
    "gps_day_level_temp as (\n",
    "select\n",
    "id,\n",
    "sp_id,\n",
    "truck_number,\n",
    "district_id,\n",
    "state_id,\n",
    "event_timestamp,\n",
    "day_flag,\n",
    "availability_flag,\n",
    "max(total_dwell_time) as total_dwell_time,\n",
    "max_by(total_is_ignition_off, total_dwell_time) as total_is_ignition_off,\n",
    "max_by(district_id_gps, total_dwell_time) as district_id_gps\n",
    "from gps_merge_temp\n",
    "where day_flag != 'others'\n",
    "group by 1,2,3,4,5,6,7,8\n",
    "),\n",
    "\n",
    "day_level_features as (\n",
    "select gps.*,\n",
    "COALESCE(d.similarity, -100) as district_similarity\n",
    "from gps_day_level_temp gps\n",
    "left join district_similarity d on gps.district_id = d.from_district_id and gps.district_id_gps = d.to_district_id\n",
    "),\n",
    "\n",
    "\n",
    "gps_trajectory as (\n",
    "select\n",
    "id,\n",
    "sp_id,\n",
    "truck_number,\n",
    "event_timestamp,\n",
    "district_id, state_id,\n",
    "availability_flag,\n",
    "array_agg(array[cast(district_similarity as int), cast(total_dwell_time as int), cast(total_is_ignition_off as int)] order by day_flag ASC) as st_features\n",
    "from day_level_features\n",
    "group by 1,2,3,4,5,6,7\n",
    "order by sp_id, event_timestamp, district_id\n",
    "),\n",
    "\n",
    "gps_district_characteristics_temp as (\n",
    "select\n",
    "f.id,\n",
    "f.truck_number,\n",
    "max_by(gps_agg.total_dwell_time, gps_agg.event_timestamp) as total_dwell_time,\n",
    "max_by(gps_agg.total_speed, gps_agg.event_timestamp) as total_speed_agg,\n",
    "max_by(gps_agg.total_is_ignition_off, gps_agg.event_timestamp) as total_is_ignition_off_agg,\n",
    "max_by(gps_agg.total_records, gps_agg.event_timestamp) as total_records_agg\n",
    "from gps_merge_temp f\n",
    "inner join gps_features_district_aggregate gps_agg on f.truck_number = gps_agg.truck_number and f.district_id = gps_agg.entity\n",
    "and f.event_timestamp>gps_agg.event_timestamp\n",
    "group by 1,2\n",
    "),\n",
    "\n",
    "gps_district_characteristics as (\n",
    "select\n",
    "id,\n",
    "ARRAY[cast(COALESCE(total_dwell_time,0) as int),\n",
    "         cast(COALESCE(total_speed_agg,0) as int),\n",
    "         cast(COALESCE(total_is_ignition_off_agg,0) as int),\n",
    "         cast(COALESCE(total_records_agg,0) as int)] as agg_features\n",
    "from gps_district_characteristics_temp\n",
    ")\n",
    "select\n",
    "o.id,o.sp_id,s.truck_number,o.event_timestamp,case when o.availability_flag = 'AVAILABLE' then 1 else 0 end as available_flag,  o.district_id,\n",
    "gps_tj.st_features,\n",
    "gps_agg.agg_features\n",
    "from output o\n",
    "inner join single_truck_sps s on s.sp_id = o.sp_id\n",
    "inner join gps_trajectory gps_tj on gps_tj.id=o.id\n",
    "inner join gps_district_characteristics gps_agg on gps_agg.id = o.id\n",
    "group by 1,2,3,4,5,6,7,8\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "311ebca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= wr.athena.read_sql_query(query, \n",
    "                                   database = config.feature_db, \n",
    "                                   workgroup = config.work_group,\n",
    "                                   s3_output = config.s3_athena_output,\n",
    "                               ctas_approach=True\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efc3385c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80537, 8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05cc362f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80537"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76707f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'sp_id', 'truck_number', 'event_timestamp', 'available_flag',\n",
       "       'district_id', 'st_features', 'agg_features'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd58d3f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5168"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['truck_number'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "118ac47a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "568"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['district_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8322572a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a3fcff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80537, 8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d55e754f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sp_id</th>\n",
       "      <th>truck_number</th>\n",
       "      <th>event_timestamp</th>\n",
       "      <th>available_flag</th>\n",
       "      <th>district_id</th>\n",
       "      <th>st_features</th>\n",
       "      <th>agg_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4384958</td>\n",
       "      <td>1822367</td>\n",
       "      <td>MH04GC5027</td>\n",
       "      <td>2021-11-02 14:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>aa681238550189035520</td>\n",
       "      <td>[[-5, 5759, 5647], [-5, 5759, 5646], [-5, 5498...</td>\n",
       "      <td>[3600, 67488, 3263, 6040]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3361978</td>\n",
       "      <td>1134577</td>\n",
       "      <td>UP21CN5275</td>\n",
       "      <td>2021-05-11 14:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>aa681238548872024064</td>\n",
       "      <td>[[-9, 4646, 3324], [-9, 3377, 3307], [-9, 2083...</td>\n",
       "      <td>[499, 31918, 359, 1724]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id    sp_id truck_number     event_timestamp  available_flag  \\\n",
       "0  4384958  1822367   MH04GC5027 2021-11-02 14:00:00               0   \n",
       "1  3361978  1134577   UP21CN5275 2021-05-11 14:00:00               0   \n",
       "\n",
       "            district_id                                        st_features  \\\n",
       "0  aa681238550189035520  [[-5, 5759, 5647], [-5, 5759, 5646], [-5, 5498...   \n",
       "1  aa681238548872024064  [[-9, 4646, 3324], [-9, 3377, 3307], [-9, 2083...   \n",
       "\n",
       "                agg_features  \n",
       "0  [3600, 67488, 3263, 6040]  \n",
       "1    [499, 31918, 359, 1724]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17322114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data['available_flag'] = training_data['availability_flag'].apply(lambda x: 1 if x == 'AVAILABLE' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0611ed93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sp_id</th>\n",
       "      <th>truck_number</th>\n",
       "      <th>event_timestamp</th>\n",
       "      <th>available_flag</th>\n",
       "      <th>district_id</th>\n",
       "      <th>st_features</th>\n",
       "      <th>agg_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4384958</td>\n",
       "      <td>1822367</td>\n",
       "      <td>MH04GC5027</td>\n",
       "      <td>2021-11-02 14:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>aa681238550189035520</td>\n",
       "      <td>[[-5, 5759, 5647], [-5, 5759, 5646], [-5, 5498...</td>\n",
       "      <td>[3600, 67488, 3263, 6040]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id    sp_id truck_number     event_timestamp  available_flag  \\\n",
       "0  4384958  1822367   MH04GC5027 2021-11-02 14:00:00               0   \n",
       "\n",
       "            district_id                                        st_features  \\\n",
       "0  aa681238550189035520  [[-5, 5759, 5647], [-5, 5759, 5646], [-5, 5498...   \n",
       "\n",
       "                agg_features  \n",
       "0  [3600, 67488, 3263, 6040]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52198cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data = training_data[training_data['agg_features'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0779b71f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'sp_id', 'truck_number', 'event_timestamp', 'available_flag',\n",
       "       'district_id', 'st_features', 'agg_features'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "74dfa96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[['st_features','available_flag']].to_csv('avail_manifest_v0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba095667",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-11 09:00:54.154643: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/amazon/efa/lib64:/opt/amazon/openmpi/lib64:/usr/local/lib:/usr/lib:/lib:\n",
      "2022-01-11 09:00:54.154704: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers import LSTM, Dropout, Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Embedding,Reshape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "91007e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'sp_id', 'truck_number', 'event_timestamp', 'available_flag',\n",
       "       'district_id', 'st_features', 'agg_features'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e85ef21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([  -5, 5759, 5647], dtype=int32),\n",
       "       array([  -5, 5759, 5646], dtype=int32),\n",
       "       array([  -5, 5498, 5205], dtype=int32),\n",
       "       array([  -5, 4958, 4665], dtype=int32),\n",
       "       array([  -5, 3518, 3239], dtype=int32)], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['st_features'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c8347a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80537, 8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f8b65370",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-11 09:01:33.473755: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-01-11 09:01:33.473817: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-16-42-212): /proc/driver/nvidia/version does not exist\n",
      "2022-01-11 09:01:33.474560: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "output = np.array(training_data.available_flag.to_list())\n",
    "output = tf.convert_to_tensor(output, np.int8)\n",
    "\n",
    "### LSTM Features\n",
    "st_features = []\n",
    "for i in training_data.st_features.to_list():\n",
    "    i = i.tolist()\n",
    "    k = []\n",
    "    for j in i:\n",
    "        k.append(j.tolist())\n",
    "    st_features.append(k)\n",
    "\n",
    "st_features = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    st_features, maxlen=5,padding=\"post\"\n",
    ")\n",
    "\n",
    "st_features = tf.convert_to_tensor(st_features, np.int8)\n",
    "\n",
    "\n",
    "## agg features\n",
    "\n",
    "\n",
    "\n",
    "agg_features = []\n",
    "for i in training_data.agg_features.to_list():\n",
    "    i = i.tolist()\n",
    "    agg_features.append(i)\n",
    "    \n",
    "agg_features = tf.convert_to_tensor(agg_features, np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce756671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gps_characteristics = []\n",
    "\n",
    "# for i in range(len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c43e1840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def Find_Optimal_Cutoff(target, predicted):\n",
    "    fpr, tpr, threshold = roc_curve(target, predicted)\n",
    "    i = np.arange(len(tpr)) \n",
    "    roc = pd.DataFrame({'tf' : pd.Series(tpr-(1-fpr), index=i), 'threshold' : pd.Series(threshold, index=i)})\n",
    "    roc_t = roc.iloc[(roc.tf-0).abs().argsort()[:1]]\n",
    "\n",
    "    return list(roc_t['threshold']) \n",
    "\n",
    "class prediction_history(Callback):\n",
    "    def __init__(self):\n",
    "        self.predhis = []\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.predhis.append(model.predict([x_test]))\n",
    "\n",
    "predictions=prediction_history()\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=4, min_delta=0)\n",
    "bst_model_path =  'truck_availability_gps_only_model.h5'\n",
    "model_checkpoint = ModelCheckpoint(bst_model_path, save_best_only=True, save_weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c2fbd0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timesteps = st_features.shape[1]\n",
    "n_features = st_features.shape[2]\n",
    "n_agg_features = agg_features.shape[1]\n",
    "# n_agg_features = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "baeecae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_speed_agg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cec70d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 5, 3)]       0           []                               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 200)          163200      ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 200)          0           ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 4)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 204)          0           ['dropout[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256)          52480       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 128)          32896       ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 64)           8256        ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1)            65          ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 256,897\n",
      "Trainable params: 256,897\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ts_input = Input(shape=(n_timesteps,n_features))\n",
    "main_input_lstm = LSTM(200, activation='relu')(ts_input)\n",
    "st_input = Dropout(0.5)(main_input_lstm)\n",
    "\n",
    "agg_input = Input(shape=(n_agg_features,))\n",
    "merged = tf.keras.layers.Concatenate(axis=1)([st_input,agg_input])\n",
    "\n",
    "\n",
    "x = Dense(256, activation='relu')(merged)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "main_output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=[ts_input,agg_input], outputs= [main_output])\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ad837cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80537, 8)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e42e93c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80537"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "edde4c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(st_features, output, \n",
    "#           epochs=30,  batch_size=1024, \n",
    "#           verbose = True, validation_split=0.2,\n",
    "#           callbacks=[model_checkpoint, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6b6693bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a229bee6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5dc76b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "59/59 [==============================] - 9s 137ms/step - loss: 0.8749 - accuracy: 0.5630 - val_loss: 0.6643 - val_accuracy: 0.6120\n",
      "Epoch 2/50\n",
      "59/59 [==============================] - 7s 125ms/step - loss: 0.6616 - accuracy: 0.6278 - val_loss: 0.6406 - val_accuracy: 0.6530\n",
      "Epoch 3/50\n",
      "59/59 [==============================] - 9s 158ms/step - loss: 0.6397 - accuracy: 0.6517 - val_loss: 0.6336 - val_accuracy: 0.6595\n",
      "Epoch 4/50\n",
      "59/59 [==============================] - 8s 134ms/step - loss: 0.6266 - accuracy: 0.6623 - val_loss: 0.6290 - val_accuracy: 0.6630\n",
      "Epoch 5/50\n",
      "59/59 [==============================] - 8s 127ms/step - loss: 0.6191 - accuracy: 0.6675 - val_loss: 0.6259 - val_accuracy: 0.6684\n",
      "Epoch 6/50\n",
      "59/59 [==============================] - 8s 128ms/step - loss: 0.6125 - accuracy: 0.6730 - val_loss: 0.6214 - val_accuracy: 0.6702\n",
      "Epoch 7/50\n",
      "59/59 [==============================] - 7s 127ms/step - loss: 0.6063 - accuracy: 0.6785 - val_loss: 0.6205 - val_accuracy: 0.6714\n",
      "Epoch 8/50\n",
      "59/59 [==============================] - 8s 132ms/step - loss: 0.6012 - accuracy: 0.6828 - val_loss: 0.6254 - val_accuracy: 0.6643\n",
      "Epoch 9/50\n",
      "59/59 [==============================] - 8s 129ms/step - loss: 0.5959 - accuracy: 0.6880 - val_loss: 0.6238 - val_accuracy: 0.6646\n",
      "Epoch 10/50\n",
      "59/59 [==============================] - 8s 133ms/step - loss: 0.5905 - accuracy: 0.6912 - val_loss: 0.6205 - val_accuracy: 0.6693\n",
      "Epoch 11/50\n",
      "59/59 [==============================] - 8s 128ms/step - loss: 0.5837 - accuracy: 0.6950 - val_loss: 0.6242 - val_accuracy: 0.6728\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f70bbf60d00>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([st_features,agg_features], output, \n",
    "          epochs=50,  batch_size=1024, \n",
    "          verbose = True, validation_split=0.25,\n",
    "          callbacks=[model_checkpoint, early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8019f7c0",
   "metadata": {},
   "source": [
    "# Train without "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a51057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(features_list),len(features_list[0]),len(features_list[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8389f188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "02a7c8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_list = np.array(sequences_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "59f2b4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20337*25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5b68e724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_list = np.reshape(features_list,( features_list.shape[0],features_list.shape[1],4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22e45350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_list=np.array(features_list).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ee59c1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# tf.convert_to_tensor(features_list, dtype=tf.int32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e60d1010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (features_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f10d5603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit([features_list[:int(len(features_list)*.8)]], output[:int(len(features_list)*.8)], epochs=10,batch_size=10,\n",
    "#           validation_data = ([features_list[int(len(features_list)*.8):]], output[int(len(features_list)*.8):]),\n",
    "#           verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e1a41e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Custom (feature_store)",
   "language": "python",
   "name": "feature_store"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
